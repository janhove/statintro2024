\chapter{Der $t$-Test}\label{ch:ttest}
Obwohl Randomisierungs- und Permutationstests gültige Signifikanztests
sind, deren Annahmen sich in kontrollierten Experimenten
durch das Forschungsdesign rechtfertigen lassen,
trifft man sie in der Praxis selten an.
Dies ist historischen Gründen und Trägheit zuzuschreiben.
Anno dazumal war es zu aufwendig, ein paar tausend
Permutationen der Daten durchzuackern, um
die Verteilung eines Gruppenunterschieds
oder eines Korrelationskoeffizienten unter
der Nullhypothese zu generieren.
Stattdessen wurden Signifikanztests entwickelt,
deren mathematische Herleitung zwar komplizierter
ist, die aber schneller ausgeführt werden können.
Beispiele solcher Tests sind der $t$-Test und
der $F$-Test. Dass diese so oft verwendet werden,
verdanken sie der Tatsache, dass ihre Ergebnisse oft mit
jenen der Randomisierungs- und Permutationstests übereinstimmen:
\begin{quote}
``the statistician does not carry out this very
simple and very tedious process [= Daten permutieren],
but his conclusions have no justification beyond the
fact that they agree with those which could have been
arrived at by this elementary method.''
(\citealp{Fisher1936})
\end{quote}
Im Folgenden stellen wir zunächst den $t$-Test vor, gefolgt
von Varianzanalyse und dem $F$-Test. Gerade in einfacheren kontrollierten
Experimenten wie im letzten Kapitel würde ich jedoch nicht automatisch
auf diese Annäherungen aus der Prä-Computerära zurückgreifen, sondern
einen Randomisierungs- oder Permutationstest in Erwägung ziehen.

Die Randomisierungstests aus Kapitel \ref{ch:logik} gehen davon aus,
dass allfällige beobachtete Unterschiede laut der Nullhypothese
das Resultat einer zufälligen Zuordnung
(\textit{random assignment}) sind. 
Anders ist es beim $t$-Test (und beim $F$-Test): 
Hier wird davon ausgegangen, dass allfällige beobachtete Unterschiede
laut der Nullhypothese
einer Zufallsauswahl aus einer Population (\textit{random sampling})
zugeschrieben werden können.
Genauer gesagt geht man beim \term{Einstichproben-$t$-Test} aus von 
der Nullhypothese,
dass man $n$ i.i.d.\ Beobachtungen $X_1, \dots, X_n$ hat,
die nach einer Normalverteilung mit unbekanntem Mittel $\mu$ und
unbekannter Varianz $\sigma^2$ verteilt sind. Wie wir bereits
gesehen haben (Satz \vref{th:gosset}), gilt unter diesen Annahmen, dass
\[
  T := \frac{\overline{X} - \mu}{S/\sqrt{n}} \sim t_{n-1},
\]
wo $\overline{X}$ das Mittel der $n$ Beobachtungen ist und $S$ 
die Stichprobenstandardabweichung. Wir können nun testen, 
ob die beobachteten Daten kompatibel mit einem bestimmten 
Populationsmittel $\mu_0$ sind. Konkret berechnen wir
\[
  T_0 := \frac{\overline{X} - \mu_0}{S/\sqrt{n}}
\]
und dann schlagen wir nach, wie extrem dieser Wert unter einer $t_{n-1}$-Verteilung
ist.

\mypar[Einstichproben-$t$-Test]{Beispiel}
  Wir beobachten 7 Werte mit Stichprobenmittel $\overline{X} = -2.4$
  und Stichprobenstandardabweichung $S = 5$. Wir stellen die Nullhypothese
  auf, dass diese sieben Werte zufällig aus einer Normalverteilung mit
  Mittel $\mu_0 = 1$ und unbekannter Varianz gezogen wurden.
  Der $t$-Wert zu dieser Nullhypothese beträgt
  \[
    \frac{-2.4 - 1}{5/\sqrt{7}} \approx -1.80.
  \]
  Für einen zweiseitigen $t$-Test berechnen wir zunächst den links- sowie
  den rechtsseitigen $p$-Wert.
  Dazu schlagen wir nach, wie häufig wir bei einer $t(6)$-Verteilung Werte von $-1.80$ oder kleiner
  und von $-1.80$ oder grösser antreffen; siehe Abbildung \ref{fig:t6}.
  Mit Lemma \ref{lemma:pvalue} erhalten wir den zweiseitigen $p$-Wert,
  indem wir die kleinere der so erhaltenen Zahlen verdoppeln:
<<>>=
t0 <- (-2.4 - 1)/(5/sqrt(7))
(p_l <- pt(t0, df = 7 - 1))
(p_r <- pt(t0, df = 7 - 1, lower.tail = FALSE))
(p_z <- 2 * min(p_l, p_r))
@
  Das heisst, wir erhalten einen zweiseitigen $p$-Wert von etwa $0.12$.
\parend

<<echo = FALSE, fig.width = 2*2, fig.height = 2*1.3, fig.cap = "Die Wahrscheinlichkeitsdichte einer $t_6$-Verteilung. Die Strichellinie zeigt den Wert $- 1.80$. Die eingefärbte Fläche unter der Wahrscheinlichkeitsdichte entspricht dem linksseitigen $p$-Wert zu $t = -1.80$.\\label{fig:t6}", out.width = ".4\\textwidth">>=
ggplot(data = tibble(t = c(-7, 7)),
       aes(x = t)) +
  stat_function(fun = dt, args = list(df = 6)) +
  geom_vline(xintercept = t0, linetype = 2) +
  stat_function(fun = dt, args = list(df = 6), xlim = c(-7, t0), geom = "area",
                fill = "steelblue") +
  ylab("Wsk.-Dichte")
@

Der Einstichproben-$t$-Test kann in R mit der Funktion \texttt{t.test()} ausgeführt
werden:
<<>>=
x <- rnorm(10, mean = 2, sd = 4)
t.test(x, mu = 1) # testet, ob das Mittel der Normalverteilung 1 ist
@

Das $t$-Wert-Verfahren kann so angepasst werden,
dass es für den Vergleich von zwei Gruppenmitteln geeignet ist.
Dies resultiert im \term{Zweistichproben-$t$-Test}.
Dieser geht von der Nullhypothese aus, dass zwei unabhängige Stichproben
gezogen wurden:
Die erste zählt $n_1$ Beobachtungen 
aus einer Normalverteilung mit unbekanntem Mittel $\mu_1$ und
unbekannter Varianz $\sigma^2$;
die zweite zählt $n_2$ Beobachtungen aus einer Normalverteilung 
mit unbekanntem Mittel $\mu_2$
und der gleichen unbekannten Varianz $\sigma^2$.
Unter diesen Annahmen gilt für den Unterschied zwischen den Stichprobenmitteln,
dass
\[
  \overline{X}_1 - \overline{X}_2 \sim \mathcal{N}\left(\mu_1 - \mu_2, \sigma^2\left(\frac{1}{n_1} + \frac{1}{n_2}\right)\right).
\]
Die gemeinsame Varianz $\sigma^2$
können wir nun anhand der Stichprobenvarianzen $S_1^2, S_2^2$ schätzen, und zwar so
\[
  S^2 = \frac{(n_1 - 1)S_1^2 + (n_2 - 1)S_2^2}{n_1 + n_2 - 2}.
\]
Diese Statistik nennt man die \term{gepoolte Varianz} (\textit{pooled variance}).
Man kann zeigen, dass
\[
  T := \frac{(\overline{X}_1 - \overline{X}_2) - (\mu_1 - \mu_2)}{S\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}} \sim t_{n-2}.
\]
Die Herleitung dieser Tatsache schenken wir uns, 
aber im nächsten Beispiel wird sie anhand einer Simulation illustriert.
Für einen hypothetischen Unterschied zwischen den Mitteln der Populationen
kann man also testen, ob die Daten mit diesem Unterschied kompatibel sind.

\mypar[Simulation]{Beispiel}\label{bsp:tvalues}
  Mit den folgenden Befehlen werden 20'000 Mal
  zwei Stichproben mit 3 bzw.\ 5 Beobachtungen
  aus der gleichen Normalverteilung generiert.
  Also gilt $\mu_1 - \mu_2 = 0$.
  Wir berechnen jeweils den $t$-Wert mit der \texttt{t.test()}-Funktion;
  die Einstellung \texttt{var.equal = TRUE} gibt an, dass wir davon ausgehen,
  dass die Stichproben aus Normalverteilungen mit gleicher Varianz stammen.
<<>>=
n_runs <- 20000
ttest_one_run <- function(n1, n2, sd1, sd2) {
  x1 <- rnorm(n1, mean = 0, sd = 3)
  x2 <- rnorm(n2, mean = 0, sd = 3)
  t.test(x1, x2, var.equal = TRUE)$statistic
}
n1 <- 3
n2 <- 5
t_values <- replicate(n_runs, ttest_one_run(n1, n2, 3, 3))
@
 Wenn wir die 20'000 $t$-Werte grafisch darstellen, sehen wir,
 dass ihre Verteilung einer $t$-Verteilung mit $3 + 5 - 2 = 6$ Freiheitsgraden
 entspricht (Abbildung \ref{fig:tvalues}).
<<fig.width = 2*2, fig.height = 2*1.3, fig.cap = "Simulierte und theoretische Verteilungsfunktion. Die blaue Kurve stellt die empirische Verteilungsfunktion der 20'000 simulierten $t$-Werte dar; die rote Strichellinie ist die Verteilungsfunktion der $t_6$-Verteilung.\\label{fig:tvalues}", out.width = ".4\\textwidth">>=
t_values |> 
  tibble() |> 
  ggplot(aes(t_values)) +
  stat_ecdf(colour = "darkblue") +
  stat_function(fun = pt, args = list(df = n1 + n2 - 2),
                colour = "red", linetype = "dashed") +
  xlab("t") +
  xlim(-7, 7) +
  ylab("kumulative Wsk.")
@
Die Warnung sagt lediglich, dass einige der $t$-Werte in der Simulation
ausserhalb des Intervalls $[-7, 7]$ liegen.
\parend

\mypar[Zweistichproben-$t$-Test]{Beispiel}
  Wir beobachten zwei Stichproben. Wir gehen von der Nullhypothese aus,
  dass diese aus unabhängigen Beobachtungen aus Normalverteilungen mit der
  gleichen Varianz stammen und dass sich die Mittel dieser Normalverteilungen
  um $\mu_1 - \mu_2 = -2$ Einheiten unterscheiden.
  Für die erste Stichprobe erhalten wir $n_1 = 7, \overline{X}_1 = 3.4, S_1^2 = 4$.
  Für die zweite Stichprobe erhalten wir $n_2 = 10, \overline{X}_2 = 9, S_2^2 = 5$.

  Wir berechnen
  \[
    S^2 = \frac{(7-1)4 + (10-1)5}{7+10-2} = 4.6
  \]
  und
  \[
    T
    = \frac{3.4 - 9 -(-2)}{\sqrt{S^2}\sqrt{\frac{1}{7} + \frac{1}{10}}}
    \approx -3.41.
  \]
  Wir gleichen diesen Wert mit einer $t_{15}$-Verteilung ab:
<<>>=
pooled_var <- ((7 - 1)*4 + (10 - 1)*5) / (7 + 10 - 2)
t0 <- (3.4 - 9 - (-2)) / (sqrt(pooled_var) * sqrt(1/7 + 1/10))
p_l <- pt(t0, df = 7 + 10 - 2)
p_r <- pt(t0, df = 7 + 10 - 2, lower.tail = FALSE)
(p_z <- 2 * min(p_l, p_r))
@
Also $p = 0.004$. Falls wir eine $\alpha$-Schwelle von $0.05$ hantieren,
würden wir hier die Nullhypothese verwerfen, dass die Stichproben aus Normalverteilungen
mit gleicher Varianz und mit Mitteln, die sich um bloss 2 Einheiten unterscheiden, stammen.
\parend

\mypar[$t$-Test als lineares Modell]{Bemerkung}
Der Codeabschnitt unten zeigt drei äquivalente Möglichkeiten,
um einen Zweistichproben-$t$-Test durchzuführen.
<<>>=
n1 <- 12
n2 <- 28
gruppe <- rep(c("A", "B"), times = c(n1, n2))
ergebnis <- c(rnorm(n = n1, mean = 3, sd = 1),
              rnorm(n = n2, mean = 4, sd = 1))
d <- tibble(gruppe, ergebnis)

# t.test(x1, x2, ...)
t.test(ergebnis[gruppe == "A"], ergebnis[gruppe == "B"],
       mu = 0, var.equal = TRUE)

# t.test(outcome ~ predictor, ...)
t.test(ergebnis ~ gruppe, data = d, mu = 0, var.equal = TRUE)

# lineares Modell
mod.lm <- lm(ergebnis ~ gruppe, data = d)
summary(mod.lm)$coefficients
@
Ein Zweistichproben-$t$-Test kann somit aufgefasst werden als ein lineares Modell,
in dem nur ein Gruppenunterschied modelliert wird und in dem man
von einem i.i.d.\ normalverteilten Restfehler ausgeht.

Ein Einstichproben-$t$-Test entspricht übrigens einem linearen Modell,
in dem nur der Schnittpunkt modelliert wird und in dem von einem 
i.i.d.\ normalverteilten Restfehler ausgegangen wird.
\parend

\mypar[unterschiedliche Varianzen]{Aufgabe}\label{ex:diffvar}
  Erhöhen Sie in Beispiel \ref{bsp:tvalues} die Standardabweichung
  der Normalverteilung, aus der die grössere Stichprobe stammt, von $3$
  auf $9$ und vergleichen Sie die simulierte Verteilungsfunktion mit
  der Verteilungsfunktion einer $t_6$-Verteilung. Was stellen Sie fest?
  Wären $p$-Werte, die auf einer $t_6$-Verteilung basieren in diesem
  Fall richtig kalibriert, zu gross oder zu niedrig?
  
  Senken Sie danach die Standardabweichung für die grössere Stichprobe 
  auf $1$. Was stellen Sie diesmal fest? 
  
  Ziehen Sie ein Fazit.
  
  Hinweis: Machen Sie die grössere Gruppe noch grösser, wenn Ihnen 
  das Fazit entgeht.
\parend

\mypar[$t$-Test nach Welch]{Bemerkung}
  Aufgabe \ref{ex:diffvar} hebt hervor, dass die Nullhypothese
  beim Zweistichproben-$t$-Test die Gleichheit der Populationsvarianzen
  umfasst. Es ist aber auch möglich, die Nullhypothese zu testen, dass
  die eine Stichprobe aus Normalverteilungen mit allenfalls
  unterschiedlichen Varianzen $\sigma_1^2, \sigma_2^2$ stammen, deren
  Mittel sich um einen hypothetischen Wert unterscheiden. Hierzu kann
  man den $t$-Test nach Welch verwenden. Für diesen wird die gepoolte
  Varianz etwas anders berechnet, was in anderen $t$-Werten resultiert.
  Ausserdem werden die Freiheitsgrade anders bestimmt; diese brauchen
  auch nicht länger Ganzzahlen zu sein.
  
  Das folgende Beispiel testet für simulierte Daten, ob sich die Mittel
  der Normalverteilungen, aus denen sie stammen, um $0.5$ Einheiten
  unterscheiden -- und zwar ein Mal mit dem üblichen $t$-Test
  und ein Mal mit dem $t$-Test nach Welch.
<<>>=
x1 <- rnorm(5, mean = 2, sd = 3)
x2 <- rnorm(8, mean = 3, sd = 6)
t.test(x1, x2, mu = 0.5, var.equal = TRUE) # normaler t-Test
t.test(x1, x2, mu = 0.5, var.equal = FALSE) # nach Welch
@
  
  \citet{Ruxton2006} empfiehlt, dass der $t$-Test nach Welch
  immer dann verwendet werden sollte, wenn man sonst einen Zweistichproben-$t$-Test
  durchführen würde. Selber würde ich in vielen Fällen mittlerweile
  einen Randomisierungstest bevorzugen, da dieser von einer Nullhypothese
  ausgeht, die sich einfacher rechtfertigen lässt.
\parend

\mypar[Nutzen für nicht-normalverteilte Beobachtungen]{Bemerkung}\label{bm:ttestapprox}
  Die Nullhypothese, die beim $t$-Test überprüft wird, ist recht unrealistisch,
  besagt er doch, die Daten stammen aus einer Normalverteilung.
  Normalverteilungen sind idealisierte mathematische Konstrukte.
  In Tat und Wahrheit sind echte Daten nie normalverteilt.
  Beispielsweise können sie nur Werte in einem beschränkten Bereich annehmen, oder
  sie können nur eine auflistbare (abzählbare) Anzahl von Werten annehmen.
  
  Für ausreichend grosse Stichproben kann man den $t$-Test jedoch als Annäherung
  von Random\-isierungs- und Permutationstests auffassen, wie bereits aus
  dem Zitat von Fisher am Anfang dieses Kapitels hervorging. Es gibt
  aber keine Garantie, dass diese Annäherung für eine konkrete, endliche
  Stichprobe bereits gut genug ist; 
  siehe hierzu etwa \citet[][Abschnitt 4.4]{Hesterberg2014}.
  Für einfachere Designs -- wie jene in Kapitel \ref{ch:logik} -- würde ich
  daher mittlerweile Randomisierungs- und Permutationstests bevorzugen.
  Für kompliziertere Designs und Modelle gibt es diese Möglichkeit nicht immer,
  sodass es sich trotzdem lohnt, mit den Annäherungsmethoden vertraut zu sein.
\parend 

\mypar[$t$-Tests für andere Parameterschätzungen]{Bemerkung}
$t$-Tests können auch eingesetzt werden, um
die Nullhypothese bei Parameterschätzungen,
die sich nicht auf Gruppenmittel beziehen, zu testen.
In den \texttt{summary()}-Outputs in
den vorigen Kapiteln finden Sie hierfür viele Beispiele:
\begin{itemize}
 \item Seite \pageref{sec:aoa}: Die Nullhypothesen, die überprüft werden, 
 besagen, dass die Parameter für \texttt{(Intercept)} und \texttt{AOA} 
 eigentlich gleich $0$ sind. 
 Diese erste Nullhypothese ist vermutlich für niemanden von Interesse ist, 
 da man sich kaum für den Interceptparameter interessiert und 
 da niemand behaupten würde, er dürfte gleich $0$ sein.
 Auch die zweite Nullhypothese kann kaum stimmen, denn sie besagt, dass das \texttt{AOA}
 überhaupt keinen linearen Zusammenhang zum \texttt{GJT} aufweist.

 \item Seite \pageref{sec:money}: 
 Die überprüften Nullhypothesen besagen wiederum, 
 dass die Parameter für \texttt{(Intercept)} und \texttt{n.Kondition} 
 in der Population gleich $0$ sind.
 Die $t$- und $p$-Werte für \texttt{n.Kondition} könnte man auch
 mit der \texttt{t.test()}-Funktion berechnen,
 wie wir es soeben gemacht haben.

 \item Seite \pageref{sec:strategy}:
 Wiederum besagen die überprüften Nullhypothesen,
 dass die Parameter in die Population gleich 0 sind.

 \item Seite \pageref{sec:dragan}: Idem.
 Von Interesse wäre hier allenfalls der Signifikanztest
 für den Interaktionsparameter (\texttt{DraganMitCS}).
\end{itemize}
Die obigen Tests sind exakt, wenn wir von einem i.i.d.\ normalverteilten
Restfehler ausgehen; ansonsten verstehen sie sich als Annäherungen, 
vgl.\ Bemerkung \ref{bm:ttestapprox}.

Auch für einen Korrelationskoeffizienten können wir einen $p$-Wert
mittels eines $t$-Tests berechnen. Mit den Permutationstests in Abschnitt
\vref{sec:permutationcorr} sind wir für den Korrelationskoeffizienten
für den Zusammenhang zwischen den Flanker- und Simondaten in \citet{Poarch2018}
bei einem $p$-Wert von 0.005 ausgekommen. Mit \texttt{cor.test()}
erhalten wir grundsätzlich das gleiche Resultat ($t(32) = 2.95$, $p = 0.0059$):
<<>>=
cor.test(poarch$Flanker, poarch$Simon)
@

Übrigens erhält man den gleichen $p$-Wert, wenn man diese Daten
in einem Regressionsmodell analysiert:

<<eval = FALSE>>=
# Output nicht gezeigt
poarch1.lm <- lm(Flanker ~ Simon, data = poarch)
poarch2.lm <- lm(Simon ~ Flanker, data = poarch)
summary(poarch1.lm)
summary(poarch2.lm)
@
In diesem Fall besagt die Nullhypothese, dass der Korrelations- bzw.\ $\beta$-Koeffizient
gleich $0$ ist und dass der Restfehler i.i.d.\ normalverteilt ist.
Im Falle eines nicht-normalverteilten Restfehlers versteht sich der Test als
Annäherung.
\parend