\chapter{Grundrisse der Stochastik}\label{ch:stochastik}
In diesem Kapitel schauen wir uns einige der für die quantitative Datenanalyse
wichtigsten mathematischen Konzepte an.

\section{Wahrscheinlichkeitsräume}
\subsection{Ereignisse und Wahrscheinlichkeiten}
Jass ist eine Familie von Kartenspielen, die mit einem Blatt von 36 Karten
gespielt werden: jeweils 6 bis Ass in jeder der vier Farben 
Herz, Schaufel, Ecke und Kreuz.
Wir stellen uns nun zwei einfache \term{Zufallsexperimente} vor:
\begin{enumerate}
  \item Im ersten Versuch ziehen wir zufällig eine Karte aus dem Blatt.
  \item Im zweiten Versuch ziehen wir zufällig zwei Karten aus dem Blatt,
  und zwar die eine nach der anderen. Wir merken uns dabei, welche Karte als
  erste gezogen wurde.
\end{enumerate}
Es ist klar, dass der erste Versuch 36 mögliche Ergebnisse hat.
Der zweite Versuch hat $36 \cdot 35 = 1260$ mögliche Ergebnisse,
denn die erste Karte ist eine von 36 möglichen und die zweite eine der 35 übrigen.

In beiden Versuchen können wir nun Ja-/Nein-Fragen zum Ergebnis stellen.
Im ersten Versuch wären dies einige der möglichen Ja-/Nein-Fragen:
\begin{itemize}
  \item Handelt es sich um $7\clubsuit$?
  \item Ist das Ergebnis in der folgenden Liste enthalten: $7\heartsuit, D\diamondsuit, A\spadesuit$?
  \item Steht eine gerade Zahl auf der Karte?
  \item Steht eine gerade Zahl auf der Karte oder ist die Karte schwarz ($\spadesuit, \clubsuit$)?
\end{itemize}
Mit `oder' ist übrigens immer das inklusive `oder' gemeint.
Für das exklusive `oder' verwenden wir Ausdrücke wie `A oder B, aber nicht beide'.

Im zweiten Versuch wären dies einige der möglichen Ja-/Nein-Fragen:
\begin{itemize}
  \item Ist die erste Karte $7\clubsuit$ und die zweite $8\heartsuit$?
  \item Ist eine der beiden Karten schwarz?
  \item Ist die Zahl auf der ersten Karte niedriger als die Zahl auf der zweiten?
  \item Ist die Summe der Zahlen auf den Karten gerade?
  \item Handelt es sich um zwei Asse?
\end{itemize}
Wenn wir eine solche Ja-/Nein-Frage mit `ja' beantworten, so sagen wir, dass
das entsprechende Ereignis eingetreten ist.
In der Wahrscheinlichkeitsrechnung werden Ergebnisse und Ereignisse
mithilfe der Mengentheorie formalisiert.

\mypar[Ergebnisse und Ereignisse]{Definition}
Ein \term{Ergebnis} ist ein mögliches Resultat eines Zufallsexperiments.
(Den Begriff Zufallsexperiment lassen wir hier undefiniert.)

Die Menge aller Ergebnisse eines Zufallsexperiments nennen wir den \term{Grundraum}
dieses Zufallsexperiments. Dieser Grundraum wird oft als $\Omega$ bezeichnet.

Ein \term{Ereignis} ist eine Teilmenge des Grundraums. Anders gesagt ist ein Ereignis
eine Menge von Ergebnissen, wobei diese Menge nicht alle Ergebnisse enthalten
muss und sogar leer sein darf. Das leere Ereignis bezeichnet man als $\emptyset$
oder $\{\}$.

Ein Ereignis der Form $\{\omega\}$, wo $\omega \in \Omega$ ein Ergebnis ist, bezeichnet
man als \term{Elementarereignis}.
\parend

In unserem ersten Versuch enthält der Grundraum $\Omega_1$ 36 Elemente:
\begin{align*}
  \Omega_1 = \{&6\clubsuit, 7\clubsuit, 8\clubsuit, 9\clubsuit, 10\clubsuit, B\clubsuit, D\clubsuit, K\clubsuit, A\clubsuit, \\
               &6\diamondsuit, 7\diamondsuit, 8\diamondsuit, 9\diamondsuit, 10\diamondsuit, B\diamondsuit, D\diamondsuit, K\diamondsuit, A\diamondsuit, \\
               &6\heartsuit, 7\heartsuit, 8\heartsuit, 9\heartsuit, 10\heartsuit, B\heartsuit, D\heartsuit, K\heartsuit, A\heartsuit, \\
               &6\spadesuit, 7\spadesuit, 8\spadesuit, 9\spadesuit, 10\spadesuit, B\spadesuit, D\spadesuit, K\spadesuit, A\spadesuit\}.
\end{align*}
Die Ja-/Nein-Frage \textit{Steht eine gerade Zahl auf der Karte?} entspricht
dem Ereignis
\begin{align*}
  A := \{6\clubsuit, 8\clubsuit, 10\clubsuit,
        6\diamondsuit, 8\diamondsuit, 10\diamondsuit,
        6\spadesuit, 8\spadesuit, 10\spadesuit,
        6\heartsuit, 8\heartsuit, 10\heartsuit\},
\end{align*}
das 12 Elemente zählt.
Die Ja-/Nein-Frage \textit{Ist die Karte schwarz?} entspricht dem Ereignis
\begin{align*}
  B := \{6\clubsuit, 7\clubsuit, \dots, A\clubsuit,
         6\spadesuit, 7\spadesuit, \dots, A\spadesuit\},
\end{align*}
das 18 Elemente zählt.
Die Ja-/Nein-Frage \textit{Steht eine gerade Zahl auf der Karte oder ist die Karte schwarz}
entspricht nun der mengentheoretischen \term{Vereinigung} von $A$ und $B$:
\begin{align*}
  A \cup B
  &= \textrm{$A$ oder $B$} \\
  &= \{\omega \in \Omega_1 : \omega \in A \textrm{~oder~} \omega \in B\} \\
  &= \{6\clubsuit, 7\clubsuit, \dots, A\clubsuit,
       6\spadesuit, 7\spadesuit, \dots, A\spadesuit,
        6\diamondsuit, 8\diamondsuit, 10\diamondsuit,
        6\heartsuit, 8\heartsuit, 10\heartsuit\}.
\end{align*}
Das Ereignis $A \cup B$ enthält 24 Ergebnisse.
Die Ja-/Nein-Frage \textit{Steht eine gerade Zahl auf der Karte \emph{und} ist die Karte schwarz}
entspricht dahingegen dem mengentheoretischen \term{Schnitt} von $A$ und $B$:
\begin{align*}
  A \cap B
  &= \textrm{$A$ und $B$} \\
  &= \{\omega \in \Omega_1 : \omega \in A \textrm{~und~} \omega \in B\} \\
  &= \{6\clubsuit, 8\clubsuit, 10\clubsuit,
       6\spadesuit, 8\spadesuit, 10\spadesuit\}.
\end{align*}
Die Ja-/Nein-Frage \textit{Steht \emph{keine} gerade Zahl auf der Karte?}
entspricht dann wieder dem mengentheoretischen \term{Komplement} von $A$:
\begin{align*}
  A^c
  &= \textrm{nicht $A$} \\
  &= \{\omega \in \Omega_1 : \omega \notin A\}.
\end{align*}
Wir beantworten die Ja-/Nein-Frage genau dann mit `ja',
wenn das tatsächliche Ergebnis $\omega$ im entsprechenden Ereignis $E$ enthalten ist, 
also wenn $\omega \in E$.

Im zweiten Zufallsexperiment besteht der Grundraum $\Omega_2$ aus den 1260 Tupeln,
die aus zwei ungleichen Karten bestehen.
Die Ja-/Nein-Frage \textit{Handelt es sich um zwei Asse?} entspricht nun dem
Ereignis
\begin{align*}
  C = \{&(A\clubsuit, A\diamondsuit), (A\clubsuit, A\heartsuit), (A\clubsuit, A\spadesuit),
        (A\diamondsuit, A\clubsuit), (A\diamondsuit, A\heartsuit), (A\diamondsuit, A\spadesuit), \\
        &(A\heartsuit, A\clubsuit), (A\heartsuit, A\diamondsuit), (A\heartsuit, A\spadesuit),
        (A\spadesuit, A\clubsuit), (A\spadesuit, A\diamondsuit), (A\spadesuit, A\heartsuit)\}.
\end{align*}

\mypar[diskrete Wahrscheinlichkeitsräume]{Definition}\label{def:disk_wsk}
Ein \term{diskreter Wahrscheinlichkeitsraum} besteht aus einem `auflistbaren'\footnote{In der Mathematik
spricht man von `abzählbar'. Jede endliche Menge kann aufgelistet werden und ist damit abzählbar.
Auch bestimmte unendliche Mengen können aufgelistet werden. Beispielsweise kann man die Menge
der natürlichen Zahlen $\mathbb{N} = \{0, 1, 2, \dots\}$ problemlos auflisten.
Auch die Ganzzahlen $\mathbb{Z}$ können aufgelistet werden: $\mathbb{Z} = \{0, 1, -1, 2, -2, \dots\}$.
Sogar die rationalen Zahlen (Bruchzahlen) $\mathbb{Q}$ können (etwas mühsamer) aufgelistet werden:
\begin{align*}
\mathbb{Q} = \{&0/1, 1/1, -1/1, 1/2, -1/2, 2/1, -2/1, 1/3, -1/3, 3/1, -3/1, \\
               &1/4, -1/4, 2/3, -2/3, 4/1, -4/1, 3/2, -3/2, \dots\}.
\end{align*}
Die reellen Zahlen $\mathbb{R}$ können jedoch nachweisbar nicht aufgelistet werden.} Grundraum
$\Omega$ und einer Abbildung (Funktion) $\Prob$, die jedem Ereignis eine Zahl zwischen
$0$ und $1$ (beide inklusive) zuordnet. Diese Abbildung legt für jedes Ereignis fest, zu welcher
Wahrscheinlichkeit es eintritt.
Dazu muss die Abbildung $\Prob$ folgende Bedingungen (Axiome) genügen:
\begin{enumerate}
  \item Für jedes Ereignis $E$ gilt $\Prob(E) \geq 0$. Das heisst, Wahrscheinlichkeiten sind nicht-negativ.
  \item $\Prob(\Omega) = 1$. Mit anderen Worten: Die Wahrscheinlichkeit, \emph{irgendein} Ergebnis zu beobachten, liegt bei $1$.
  \item Sei $A_1, A_2, A_3, \dots$ eine (endliche oder unendliche) Liste von Ereignissen.
        Wenn jedes Ergebnis in höchstens einem der aufgelisteten Ereignisse vorkommt,
        so ist die Wahrscheinlichkeit, dass \emph{irgendeines} der aufgelisteten Ereignisse eintritt,
        gerade die Summe der Wahrscheinlichkeiten der einzelnen Ereignisse. In Symbolen:
        Wenn für jedes $i \neq j$ gilt, dass $A_i \cap A_j = \emptyset$, so gilt
        \[
          \Prob\left(\bigcup_{i = 1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} \Prob(A_i).
        \]
         \parend
\end{enumerate}

\mypar[Rechenregeln für Wahrscheinlichkeiten]{Lemma}
Aus den Bedingungen an der Abbildung $\Prob$ können ein paar wichtige Rechenregeln
abgeleitet werden.
\begin{enumerate}
  \item Für jedes Ereignis $A$ gilt $A \cup A^c = \Omega$ und $A \cap A^c = \emptyset$.
  Daher gilt
  \[
    1 = \Prob(\Omega) = \Prob(A \cup A^c) = \Prob(A) + \Prob(A^c),
  \]
  also
  \[
    \Prob(A^c) = 1 - \Prob(A).
  \]
  Da $\Omega^c = \emptyset$, gilt insbesondere $\Prob(\emptyset) = 0$.

  \item Für zwei Ereignisse $A, B$ bezeichnen wir mit $A \setminus B$
  das Ereignis, dass das Ergebnis in $A$ aber nicht in $B$ liegt:
  \[
    A \setminus B = \{\omega \in \Omega: \omega \in A, \omega \notin B\}.
  \]
  Dann gilt
  \[
    A \cup B = (A \setminus B) \cup (B \setminus A) \cup (A \cap B),
  \]
  wobei $A \setminus B, B \setminus A, A \cap B$ nicht überlappen.
  Somit gilt
  \[
    \Prob(A \cup B) = \Prob((A \setminus B) \cup (B \setminus A) \cup (A \cap B))
                    = \Prob(A \setminus B) + \Prob(B \setminus A) + \Prob(A \cap B).
  \]
  Nun gilt auch $A = (A \setminus B) \cup (A \cap B)$ und $B = (B \setminus A) \cup (A \cap B)$.
  Folglich
  \begin{align*}
    \Prob(A \cup B)
    &= \Prob(A \setminus B) + \Prob(B \setminus A) + \Prob(A \cap B) \\
    &= \Prob(A) - \Prob(A \cap B) + \Prob(B) - \Prob(A \cap B) + \Prob(A \cap B) \\
    &= \Prob(A) + \Prob(B) - \Prob(A \cap B) \\
    &\leq \Prob(A) + \Prob(B).
  \end{align*}
  In Worten: Die Wahrscheinlichkeit, dass irgendeines von zwei Ereignissen eintrifft,
  ist die Summe der Wahrscheinlichkeiten der beiden Ereignisse minus
  die Wahrscheinlichkeit, dass sie beide eintreffen.

  \item In diskreten Wahrscheinlichkeitsräumen lässt sich jedes Ereignis schreiben
  als die Vereinigung einer Liste von Elementarereignissen. Diese Elementarereignisse
  überlappen nicht. Also wird die Wahrscheinlichkeit jedes Ereignisses bereits
  festgelegt von den Wahrscheinlichkeiten der Elementarereignissen.
  \parend
\end{enumerate}

\mypar[Diskrete Gleichverteilung auf $\Omega_1$]{Beispiel}
Wir nehmen das erste Zufallsexperiment wieder auf und nehmen an,
dass jede Karte die gleiche Wahrscheinlichkeit hat, gezogen zu werden.
Das heisst, $\Prob(\{\omega\}) = 1/36$ für jedes $\omega \in \Omega_1$.
Wir sagen in diesem Fall, dass $\Prob$ eine \term{Gleichverteilung} auf
$\Omega_1$ ist.

Das Ereignis $A$ (`Auf der Karte steht eine gerade Zahl') zählt 12 Ergebnisse
und tritt folglich zu einer Wahrscheinlichkeit von $12 \cdot 1/36 = 1/3$ ein.
Das Ereignis $B$ (`Die Karte ist schwarz') zählt 18 Ergebnisse, sodass
$\Prob(B) = 18/36 = 1/2$.
Das Ereignis $A \cap B$ zählt 6 Ergebnisse, sodass $\Prob(A \cap B) = 6/36 = 1/6$.
Folglich gilt $\Prob(A \cup B) = \Prob(A) + \Prob(B) - \Prob(A \cap B) = 2/3$.
\parend

\mypar[Zipfverteilung]{Beispiel} Wir betrachten eine Sprache mit einem
endlichen Wortschatz $\Omega$. Die Wörter bezeichnen wir ihrer Frequenz absteigend
nach mit $\omega_1, \omega_2, \dots, \omega_n$. Hierbei gehen wir davon
aus, dass diese Frequenzen paarweise unterschiedlich sind.
Das Zipfmodel besagt, dass die relative Häufigkeit eines Wortes in einer Sprache
(in etwa) umgekehrt proportional zu seinem Frequenzrang ist, also dass
\[
  \Prob(\{\omega_k\}) = C_n\frac{1}{k}
\]
für irgendeine von $n$ abhängige Konstante $C_n$ und für alle $k = 1, \dots, n$.
Es muss gelten, dass
\[
  1 = \Prob(\Omega) = \Prob(\bigcup_{k = 1}^n \{\omega_k\}) = \sum_{k=1}^n C_n\frac{1}{k} = C_n \sum_{k=1}^n \frac{1}{k}.
\]
Also
\[
  C_n = \frac{1}{\sum_{k=1}^n\frac{1}{k}} = \frac{1}{H_n}
\]
wo $H_n$ die $n$-te harmonische Zahl ist.
Für $n = 10$ erhalten wir laut diesem Modell folgende relative Häufigkeiten:
<<>>=
n <- 10
woerter <- 1:n
Hn <- sum(1/woerter)
tibble(Wort = woerter,
       rel.Häufigkeit  = 1/Hn * 1/woerter)
@
Dieses Modell geht übrigens deswegen von einem endlichen Wortschatz aus,
weil $\sum_{k=1}^{\infty}\frac{1}{k}$ gegen unendlich divergiert.
\parend

\mypar[unendlicher diskreter Wahrscheinlichkeitsraum]{Beispiel}\label{bsp:2k}
  Wir stellen uns einen Zufallsgenerator vor,
  der jede Zahl $k = 1, 2, 3, \dots$ zu einer Wahrscheinlichkeit von $1/2^k$
  ausspuckt. Der Grundraum besteht nun aus allen natürlichen Zahlen $k \geq 1$.
  Da
  \[
    \sum_{k=1}^{\infty} \Prob(\{k\}) = \sum_{k=1}^{\infty} \frac{1}{2^k} = \frac{1}{2} + \frac{1}{4} + \frac{1}{8} + \dots = 1,
  \]
  handelt es sich hier um einen gültigen diskreten Wahrscheinlichkeitsraum.
  Die Wahrscheinlichkeit, dass man eine gerade Zahl generiert, beträgt
  \[
    \sum_{k=1}^{\infty} \Prob(\{2k\}) = \sum_{k=1}^{\infty} \frac{1}{2^{2k}} = \sum_{k=1}^{\infty} \frac{1}{4^k} = \frac{1}{4} + \frac{1}{16} + \frac{1}{64} + \dots = \frac{1}{3}.
  \]
\parend

Diskrete Wahrscheinlichkeitsräume lassen sich relativ einfach beschreiben,
denn sie werden komplett charakterisiert von den Elementarereignissen
und den Wahrscheinlichkeiten, die wir ihnen zuordnen.
Für viele Anwendungen sind diskrete Wahrscheinlichkeitsräume jedoch ungeeignet,
da sich der Grundraum besser als die Menge der reellen Zahlen ($\mathbb{R}$)
auffassen lässt. Diese Menge kann jedoch nicht aufgelistet werden.
Es stellt sich nun heraus, dass wir in solchen Fällen
nicht länger beliebige Teilmengen des Grundraums als Ereignisse betrachten können
und sinnvolle Wahrscheinlichkeitsaussagen über diese machen können.\label{comment:messbar}
Auf die Gründe dafür wollen wir hier nicht eingehen. Praktisch gesehen
hält sich das Problem glücklicherweise in Grenzen, denn die Teilmengen, die
man nicht als Ereignis betrachten kann, sind recht schwierig zu konstruieren
und für uns nicht relevant. In der nächsten Definition verzichten wir daher
auf eine nähere Beschreibung der Eigenschaften, welche die Familie von
Ereignissen, über die man Wahrscheinlichkeitsaussagen machen kann, erfüllen muss.

\mypar[allgemeine Wahrscheinlichkeitsräume]{Definition}
Ein \term{allgemeiner Wahrscheinlichkeitsraum} besteht aus (1) einer
(auflistbaren oder nicht-auflistbaren) Grundmenge $\Omega$,
(2) einer Familie von Ereignissen, über die man Wahrscheinlichkeitsaussagen machen kann,
und (3) einer Abbildung $\Prob$, die jedem dieser Ereignissen eine Wahrscheinlichkeit
zuordnet. Die Abbildung $\Prob$ hat die gleichen Eigenschaften wie
in Definition \ref{def:disk_wsk}.
\parend

\mypar[kontinuierliche Gleichverteilung]{Beispiel}\label{bsp:rad}
Die Kreislinie eines Glücksrads ist wie in Abbildung \ref{fig:kreis} mit Zahlen von
0 bis 360 (exklusive) vermerkt. Jedes Mal, wenn der Pfeil gedreht wird, bleibt er
an einer zufälligen Stelle auf der Kreislinie stehen. Wir können mit beliebiger
Genauigkeit ablesen, bei welchem Zahlenwert der Pfeil stehen bleibt.

Der Grundraum in diesem Beispiel besteht aus allen reellen Zahlen im Intervall
$[0, 360)$. Diese Menge kann zwar nicht aufgelistet werden, aber über alles, was
wir sinnvollerweise als Ereignis betrachten möchten, können wir dennoch
Wahrscheinlichkeitsaussagen machen.
So ist die Wahrscheinlichkeit, dass der Pfeil irgendwo zwischen den
Zahlen $a$ und $b$ ($a, b \in [0, 360), a \leq b$) landet, proportional zur Länge des
Intervalls $[a, b)$, also $b - a$. Da $\Prob([0, 360)) = 1$ gelten muss, folgt
\[
  \Prob([a, b)) = \frac{b - a}{360}.
\]
Beispielsweise beträgt die Wahrscheinlichkeit, dass der Pfeil zwischen 45 und 93
stehen bleibt $\frac{93 - 45}{360} \approx 0.133$.

Etwas kontraintuitiv beträgt in diesem Beispiel die Wahrscheinlichkeit, dass
der Pfeil an einem bestimmten Wert $a \in [0, 360)$ stehen bleibt, genau 0,
und dies für alle $a \in [0, 360)$. Dies liegt daran, dass ein einzelner
Punkt die Länge 0 hat. Aus der dritten Eigenschaft von $\Prob$ folgt nun,
dass sogar die Wahrscheinlichkeit, dass der Pfeil an irgendeinem Punkt,
der in einer unendlich langen Liste vorkommt, stehen bleibt, genau 0 beträgt.
Beispielsweise gilt
  \[
    \Prob(\{1, \frac{1}{2}, \frac{1}{3}, \frac{1}{4}, \dots\}) = 0.
  \]
Dies beisst sich nicht mit der Bedingung, dass $\Prob([0, 360)) = 1$ gelten soll:
Das Intervall $[0, 360)$ kann nicht als eine solche Liste geschrieben werden.

Eine Konsequenz von der Tatsache, dass in diesem Beispiel
individuelle Punkte Wahrscheinlichkeit 0 haben, ist, dass man ohne Bedenken
die Randpunkte den Intervallen hinzufügen darf oder sie weglassen kann:
\[
  \Prob([a, b]) = \Prob((a, b)) = \Prob([a, b)) = \Prob((a, b]).
\]
\parend

\begin{figure}[tp]
\begin{center}
  \includegraphics[width = .33\textwidth]{figs/kreis}
\caption{Ein Glücksrad.}
\label{fig:kreis}
\end{center}
\end{figure}

\subsection{Unabhängigkeit}

\mypar[Unabhängigkeit (1)]{Definition}
Wir sagen, dass zwei Ereignisse $A$ und $B$ \term{unabhängig} sind, falls
\[
  \Prob(A \cap B) = \Prob(A)\Prob(B)
\]
gilt. Salopper sagt man in diesem Fall auch, dass $A$ und $B$ unabhängig
\emph{voneinander} sind oder dass $A$ unabhängig von $B$ ist (oder umgekehrt).
\parend

\mypar{Beispiel}
Das Ereignis $\emptyset$ ist unabhängig von jedem anderen Ereignis,
denn für jedes Ereignis $B$ gilt $\emptyset \cap B = \emptyset$. Somit
\[
  \Prob(\emptyset \cap B) = \Prob(\emptyset) = 0 = 0\cdot \Prob(B) = \Prob(\emptyset)\Prob(B).
\]
Ebenso ist das Ereignis $\Omega$ unabhängig von jedem anderen Ereignis,
denn für jedes Ereignis $B$ gilt $\Omega \cap B = \Omega$. Somit
\[
  \Prob(\Omega \cap B) = \Prob(B) = 1\cdot \Prob(B) = \Prob(\Omega)\Prob(B).
\]
\parend

\mypar{Beispiel}
Die Ereignisse $A$ (`Auf der Karte steht eine gerade Zahl')
und $B$ (`Die Karte ist schwarz') aus dem ersten Zufallsexperiment
sind unabhängig, denn
\[
  \Prob(A \cap B) = \frac{6}{36} = \frac{12}{36} \cdot \frac{18}{36} = \Prob(A)\Prob(B).
\]
Die Ereignisse $A \cup B$ und $A \cap B$ sind jedoch nicht unabhängig, denn
\[
  \Prob((A \cup B) \cap (A \cap B))
  = \Prob(A \cap B)
  = \frac{1}{6} \neq \frac{2}{3} \cdot \frac{1}{6}
  = \Prob(A \cup B)\Prob(A \cap B).
\]
\parend

\mypar{Aufgabe}
Betrachten wir das zweite Zufallsexperiment. Sind die Ereignisse
`Die erste Karte ist ein Ass' und `Die zweite Karte ist ein Ass' unabhängig?
\parend

\mypar{Aufgabe}
  Es seien $F$ und $G$ irgendwelche Ereignisse mit $\Prob(F) = 0.6$,
  $\Prob(G) = 0.2$ und $\Prob(F \cup G) = 0.72$. Sind $F$ und $G$ unabhängig?
\parend

\mypar[Unabhängigkeit (2)]{Definition} Wir sagen, dass $n$ Ereignisse $A_1, \dots, A_n$
\term{paarweise unabhängig} sind, falls jedes Paar von Ereignissen aus diesen $n$ Ereignissen unabhängig
ist.

Wir sagen, dass $n$ Ereignissen $A_1, \dots, A_n$ \term{unabhängig} sind, falls für \emph{jede}
Untermenge $I \subset \{1, \dots, n\}$ gilt, dass
\[
  \Prob\left(\cap_{i \in I} A_i\right) = \prod_{i \in I}\Prob(A_i).
\]
In Worten: Für jede Auswahl von höchstens $n$ Ereignissen ist die
Wahrscheinlichkeit, dass all die ausgewählten Ereignisse eintreten,
gleich dem Produkt der Wahrscheinlichkeiten, dass sie einzeln eintreten.
Unabhängigkeit impliziert paarweise Unabhängigkeit. Dies sieht man, wenn man
alle Untermengen $I$ mit zwei Ereignissen überprüft.
\parend

\mypar{Beispiel}
Wir definieren den Grundraum
\[
  \Omega := \{(0, 0, 0), (0, 1, 1), (1, 0, 1), (1, 1, 0)\}
\]
versehen mit einer diskreten Gleichverteilung, also $\Prob(\{\omega\}) = 1/4$
für alle $\omega \in \Omega$. Wir betrachten die Ereignisse
$A :=$ `Die erste Zahl ist eine 1',
$B :=$ `Die zweite Zahl ist eine 1'
und $C :=$ `Die dritte Zahl ist eine 1'.
Sie können nun überprüfen, dass $A, B, C$ paarweise unabhängig sind.
Jedoch gilt
\[
  \Prob(A \cap B \cap C) = 0 \neq \frac{1}{2} \cdot \frac{1}{2} \cdot \frac{1}{2} = \Prob(A)\Prob(B)\Prob(C).
\]
Somit sind $A, B, C$ nicht unabhängig.
\parend

Die nächste Definition brauchen wir nur, um später die Gesetze der grossen Zahlen zu verstehen.

\mypar[Unabhängigkeit (3)]{Definition} Haben wir eine Familie von unendlich vielen
Ereignissen, so sagen wir, dass diese unabhängig ist, wenn jede endliche Teilfamilie
unabhängig ist (im Sinne der vorigen Definition). \parend

\subsection{Bedingte Wahrscheinlichkeiten}
\mypar[bedingte Wahrscheinlichkeit]{Definition}
  Seien $A$ und $B$ Ereignisse mit $\Prob(B) > 0$.
  Dann bezeichnen wir
  \[
    \Prob(A | B) := \frac{\Prob(A \cap B)}{\Prob(B)}
  \]
  als die \term{bedingte Wahrscheinlichkeit von $A$ gegeben $B$}.
  Die bedingte Wahrscheinlichkeit von $A$ gegeben $B$ drückt
  die Wahrscheinlichkeit aus,
  dass $A$ eintritt, wenn man bereits weiss, dass $B$ eintritt.
\parend

\mypar{Bemerkung} Sind $A$ und $B$ unabhängig mit $\Prob(B) > 0$, so gilt
  \begin{align*}
    \Prob(A | B)
    &= \frac{\Prob(A \cap B)}{\Prob(B)}   & [\textrm{Definition bedingte Wsk.}] \\
    &= \frac{\Prob(A)\Prob(B)}{\Prob(B)}  & [\textrm{Definition Unabhängigkeit}] \\
    &= \Prob(A).                          &
  \end{align*}
  Dies entspricht der Intuition, dass bei unabhängigen Ereignissen $A$ und $B$
  das Wissen darüber, ob $B$ eintritt oder nicht, einem keine Information darüber
  gibt, ob auch $A$ eintritt.
\parend

\mypar{Beispiel}
  Im Glücksradbeispiel können wir uns fragen, wie gross die Wahrscheinlichkeit
  ist, dass der Pfeil zwischen 90 und 270 stehen bleibt (`$A$'), angenommen,
  dass er zwischen 0 und 120 stehen bleibt (`$B$').
  Es gilt $\Prob(B) = (120 - 0)/360 = 1/3$ und $\Prob(A \cap B) = (120 - 90)/(360) = 1/12$.
  Also
  \[
    \Prob(A | B) = \frac{\Prob(A \cap B)}{\Prob(B)} = \frac{1/12}{1/3} = \frac{1}{4}.
  \]
  Da $\Prob(A) = (270-90)/360 = 1/2$, gilt $\Prob(A | B) \neq \Prob(A)$.
  Also sind $A, B$ nicht unabhängig.
\parend

Manchmal nützlich ist der Satz der totalen Wahrscheinlichkeit,
der es uns erlaubt, ein komplexes Ereignis zu zerlegen in handlicheren
Ereignissen.
\mypar[totale Wahrscheinlichkeit]{Satz}
Seien $E_1, E_2, \dots$ nicht-überlappende Ereignisse, die zusammen den
ganzen Grundraum umfassen, also $E_1 \cup E_2 \cup \dots = \Omega$.
Es gelte weiter $\Prob(E_k) > 0$ für alle $k = 1, 2, \dots$. Dann gilt für jedes
Ereignis $A$:
\[
  \Prob(A) = \sum_{k=1}^{\infty} \Prob(A | E_k) \Prob(E_k).
\]
Dies sieht man so:
\begin{align*}
  \Prob(A)
  &= \Prob(A \cap \Omega)  \\
  &= \Prob(A \cap \bigcup_{k=1}^\infty E_k) \\
  &= \Prob\left(\bigcup_{k=1}^{\infty} (A \cap E_k)\right) \\
  &= \sum_{k=1}^{\infty} \Prob(A \cap E_k) \\
  &= \sum_{k=1}^{\infty} \Prob(A | E_k)\Prob(E_k).
\end{align*}
\parend

\mypar{Beispiel}
Betrachten wir wieder das zweite Zufallsexperiment.
Die diskrete Gleichverteilung auf $\Omega_2$ weist jedem Elementarereignis
$(\omega_1, \omega_2)$ in $\Omega_2$ eine Wahrscheinlichkeit von $1/1260$ zu.
Die Wahrscheinlichkeit, dass die erste Karte $6\clubsuit$ ist und die zweite Karte
keine 6 ist, beträgt
\[
  \frac{1}{36} \cdot \frac{36-4}{35} \approx 0.0254.
\]
Folglich beträgt die Wahrscheinlichkeit, dass die erste Karte irgendeine 6 ist
und die zweite nicht
\[
  4\left(\frac{1}{36} \cdot \frac{36-4}{35}\right) \approx 0.1016.
\]
Analog berechnet man die Wahrscheinlichkeit, dass die erste Karte irgendeine 7
ist und die zweite grösser ist:
\[
  4\left(\frac{1}{36} \cdot \frac{36-8}{35}\right) \approx 0.0889.
\]
Die Ereignisse `Die erste Karte ist eine 6', `Die erste Karte ist eine 7', \dots,
überlappen nicht und decken den ganzen Grundraum ab. Also können wir den
Satz der totalen Wahrscheinlichkeit anwenden, um die Wahrscheinlichkeit zu berechnen,
dass die erste Karte niedriger als die zweite Karte ist:
\begin{align*}
  \sum_{k = 1}^{9} 4\left(\frac{1}{36} \cdot \frac{36-4k}{35}\right)
  = \frac{4}{36\cdot 35} \sum_{k=1}^9 \left(36 - 4k\right)
  = \frac{4}{36\cdot 35}(9\cdot 36 - (4+8+\dots+36)).
\end{align*}
Das Resultat berechnen wir in R:
<<>>=
4/(36*35) * (9*36 - sum(4*seq(1, 9)))
@
Das heisst, etwa 46\%.

Etwas eleganter kann man dies auch so lösen:
Die Wahrscheinlichkeit, dass beide Karte den gleichen Rang haben,
beträgt $3/35$. Also beträgt die Wahrscheinlichkeit, dass die
beiden Karten unterschiedlichen Ranges sind $32/35$.
Es ist dann klar, dass die Wahrscheinlichkeiten, dass die erste niedriger
als die zweite ist und dass die zweite niedriger
als die erste ist, gleich sind. Daher beträgt die Wahrscheinlichkeit,
dass die erste Karte niedrigeren Ranges als die zweite ist $(32/35)/2 \approx 0.4571$.
\parend

\mypar[M\&Ms]{Aufgabe}\label{ex:mm}
  M{\&}Ms kommen in sechs Farben vor; in Tabelle \vref{tab:mandms} werden ihre relativen Frequenzen aufgelistet.
  Wir gehen davon aus, dass 
  die Population der M{\&}Ms unendlich gross ist, sodass wir unterschiedliche Auswahlen als unabhängig auffassen dürfen.
  
\begin{enumerate}
  \item Wie wahrscheinlich ist es, dass ein zufällig ausgewähltes M{\&}M rot \emph{oder} orange ist?
  \item Wie wahrscheinlich ist es, dass von zwei zufällig ausgewählten M{\&}Ms \emph{beide} rot oder orange 
  (also zwei rote, zwei orange oder ein rotes und ein oranges) sind?
  \item Wie wahrscheinlich ist es, dass von zwei zufällig ausgewählten M{\&}Ms eines rot und eines orange ist?
  \item Wie wahrscheinlich ist es, dass wenn 5 M{\&}Ms zufällig ausgewählt werden, alle blau sind?
  \item Wie wahrscheinlich ist es, dass wenn 5 M{\&}Ms zufällig ausgewählt werden, kein einziges blau ist? \parend
\end{enumerate}


\begin{table}[tbp]
\centering
\caption{Relative Frequenzen von M\&Ms nach Farbe.}
\label{tab:mandms}
\begin{tabular}{@{}lr@{}}
\toprule
Farbe  & relative Frequenz \\ \midrule
blau   & 23\%              \\
orange & 23\%              \\
gelb   & 15\% \\
grün   & 15\% \\
braun  & 12\% \\
rot    & 12\% \\
\bottomrule
\end{tabular}
\end{table}

  Sowohl in wissenschaftlichen als auch in gesellschaftlichen Diskussionen
  kommt es leider recht häufig vor, dass die bedingten Wahrscheinlichkeiten
  $\Prob(A | B)$ und $\Prob(B | A)$ miteinander verwechselt werden.
Das nächste klassische Beispiel und der darauf folgende Satz zeigen, 
wie man $\Prob(A | B)$ und $\Prob(B | A)$ richtig miteinander in Bezug zu setzt.

\mypar[medizinische Tests]{Beispiel}\label{bsp:medtest}
  Man stelle sich vor, dass bei allen Neugeborenen einen medizinischen Test
  durchgeführt wird, um eine seltene genetische Krankheit aufzuspüren, von
  der schätzungsweise 0.01\% der Neugeborenen betroffen ist.
  Der Test stuft tatsächlich Betroffene zu einer Wahrscheinlichkeit von
  97\% als krank ein. Jedoch werden auch 1\% der Neugeborenen, die
  nicht von der Krankheit betroffen sind, trotzdem als krank eingestuft.
  Wie wahrscheinlich ist es nun, dass ein Neugeborener, der als krank eingestuft
  wird, tatsächlich die Krankheit hat?

  Um diese Frage zu beantworten, können wir uns zunächst eine grosse Anzahl
  von Neugeborenen vorstellen, zum Beispiel eine Million.
  Tatsächlich krank wären dann etwa $0.0001 \cdot 10^6 = 100$ unter ihnen;
  die restlichen 999'900 wären nicht betroffen.
  Von den 100 kranken Kindern werden 97 als krank eingestuft; bei drei
  wird die Krankheit nicht sofort entdeckt.
  Von den 999'900 nicht-betroffenen Kindern werden $0.01 \cdot 999900 = 9999$
  trotzdem als krank eingestuft.
  Wenn wir nun aus den ingesamt $97 + 9999 = 10096$ als krank eingestuften
  Kindern zufällig ein Kind auswählen, so beträgt die Wahrscheinlichkeit, dass
  dieses tatsächlich von der Krankheit betroffen ist, bloss $97/10096 \approx 0.0096$,
  also nicht einmal 1\%.
\parend

Das Vorgehen aus dem vorigen Beispiel ist allgemeingültig, wie der berühmte
Satz von Bayes zeigt.

\mypar[Bayes]{Satz}
Seien $A, B$ Ereignisse mit $\Prob(A), \Prob(B) > 0$. Dann gilt
\begin{align*}
  \Prob(B | A)
  &= \frac{\Prob(B \cap A)}{\Prob(A)}     & [\textrm{Definition bedingte Wsk.}] \\
  &= \frac{\Prob(A|B)\Prob(B)}{\Prob(A)}  & [\Prob(A|B)=\Prob(A \cap B)/\Prob(B)] \\
  &= \frac{\Prob(A|B)\Prob(B)}{\Prob(A|B)\Prob(B) + \Prob(A|B^c)(1 - \Prob(B))}. & [\textrm{totale Wahrscheinlichkeit}]
\end{align*}
\parend

Angewandt auf Beispiel \ref{bsp:medtest} hiesse $B$ `Kind ist betroffen'
und $A$ `Kind wird als krank eingestuft'. Dann
$\Prob(A|B) = 0.97, \Prob(B) = 0.0001, \Prob(A | B^c) = 0.01$.
Also
\[
  \Prob(B | A) = \frac{0.97 \cdot 0.0001}{0.97 \cdot 0.0001 + 0.01 \cdot (1 - 0.0001)} \approx 0.0096.
\]

\section{Zufallsvariablen}
Beim Analysieren quantitativer Daten nehmen wir häufig an,
dass diese Daten Beobachtungen von Zufallsvariablen sind.

\mypar[Zufallsvariablen]{Definition}
  Sei $\Omega$ der Grundraum eines Wahrscheinlichkeitsraums.
  Eine \term{Zufallsvariable} $X$ assoziiert jedes Ereignis $\omega \in \Omega$
  mit einer reellen Zahl.

  Ist die Menge der möglichen Werte von $X$ auflistbar, so nennen wir
  $X$ eine \term{diskrete Zufallsvariable}.
\parend

\mypar{Beispiel}\label{bsp:obenabe}
Beim Jassen können wir die Zufallsvariable $X$ betrachten,
die jede Karte mit ihrem Wert im \textit{Obenabe}-Spiel assoziiert,
d.h.,
\begin{align*}
X(\omega) :=
\begin{cases}
  11, & \textrm{falls $\omega$ ein Ass ist,} \\
  4,  & \textrm{falls $\omega$ ein König ist,} \\
  3,  & \textrm{falls $\omega$ eine Dame ist,} \\
  2,  & \textrm{falls $\omega$ ein Bub ist,} \\
  10, & \textrm{falls $\omega$ eine 10 ist,} \\
  8,  & \textrm{falls $\omega$ eine 8 ist,} \\
  0,  & \textrm{sonst}.
\end{cases}
\end{align*}
Diese Zufallsvariable ist bloss eine von beliebig vielen, die man auf 
dem Grundraum $\Omega_1$ konstruieren kann.

Wenn wir zwei Karten ziehen, könnten wir beispielsweise eine Zufallsvariable
definieren, die den Gesamtwert der beiden Karten darstellt.
\parend

Wir können die Werte, die eine Zufallsvariable annimmt, auch als eigene
Ergebnisse betrachten. So erhalten wir einen neuen Grundraum
\[
\widetilde{\Omega} := \{X(\omega) : \omega \in \Omega_1\} = \{0, 2, 3, 4, 8, 10, 11\}.
\]
Die Wahrscheinlichkeit, dass $X$ den Wert 11 annimmt, ist hier
$4/36 = 1/9$; wir schreiben $\Prob(X = 11) = 1/9$.
Auch gilt $\Prob(X = 0) = 1/3$.
Auch wenn wir Zufallsvariablen betrachten, können wir über Ereignisse reden,
beispielsweise das Ereignis, dass $X \geq 10$ ist ($\Prob(X \geq 10) = 2/9$).

Wir widmen uns nun den wichtigsten Darstellungen und Eigenschaften von
Zufallsvariablen.

\subsection{Die Verteilungs- und Quantilfunktion}
Zufallsvariablen werden vollständig von ihrer \term{Verteilungsfunktion}
charakteristiert (vgl.\ Abschnitt \ref{sec:descriptive_cumprop}). 
Die Verteilungsfunktion $F_X$ einer Zufallsvariablen $X$
ist wie folgt definiert:
\[
  F_X(r) := \Prob(X \leq r)
\]
für jede reellen Zahl $r$.

Greifen wir das obige Beispiel wieder auf, so können wir eine Tabelle
mit den kumulativen Wahrscheinlichkeiten zusammenbasteln:
{
\centering
\begin{tabular}{l|lllllll}
\hline
Wert                              & 0     & 2  & 3 & 4 & 8 & 10 & 11  \\
Wahrscheinlichkeit                & 0.333 & 0.111 & 0.111 & 0.111 & 0.111 & 0.111 & 0.111 \\
kumulative Wahrscheinlichkeit     & 0.333 & 0.444 & 0.555 & 0.666 & 0.777 & 0.888 & 1 \\
\hline
\end{tabular}
}

Folglich gelten etwa $F_X(-1) = 0, F_X(2.5) = 0.444$ und $F_X(1.2) = 1$.
Abbildung \ref{fig:fx} stellt die Verteilungsfunktion von $X$ dar.

<<echo = FALSE, fig.cap = "Verteilungsfunktion der Punktzahl einer Jasskarte beim \\textit{Obenabe}.\\label{fig:fx}", fig.width = 4, fig.height = 3, out.width=".4\\textwidth">>=
plot(1, 1, type = "n", xlim = c(-2, 13), ylim = c(0, 1),
     xlab = "r", ylab = bquote(F[x](r)))
segments(-3, 0, 0)
segments(0, 1/3, 2)
segments(2, 1/3 + 1/9, 3)
segments(3, 1/3 + 1/9 + 1/9, 4)
segments(4, 1/3 + 1/9 + 1/9 + 1/9, 8)
segments(8, 1/3 + 1/9 + 1/9 + 1/9 + 1/9, 10)
segments(10, 1/3 + 1/9 + 1/9 + 1/9 + 1/9 + 1/9, 11)
segments(11, 1/3 + 1/9 + 1/9 + 1/9 + 1/9 + 1/9 + 1/9, 14)
points(0, 1/3, pch = 16)
points(2, 1/3 + 1/9, pch = 16)
points(3, 1/3 + 1/9 + 1/9, pch = 16)
points(4, 1/3 + 1/9 + 1/9 + 1/9, pch = 16)
points(8, 1/3 + 1/9 + 1/9 + 1/9 + 1/9, pch = 16)
points(10, 1/3+1/9+1/9+1/9 + 1/9 + 1/9,pch = 16)
points(11, 1/3+1/9+1/9+1/9 + 1/9 + 1/9 + 1/9,pch = 16)
@

Kennen wir die Verteilungsfunktion einer Zufallsvariablen, so können wir
Wahrscheinlichkeitsaussagen darüber machen, ob die Zufallsvariable in einem
bestimmten Intervall liegt:
\begin{align*}
  \Prob(X \in (-\infty, b]) = \Prob(X \leq b) = F_X(b), \\
  \Prob(X \notin (-\infty, a]) = \Prob(X > a) = 1 - F_X(a)
\end{align*}
und
\[
  \Prob(X \in (a, b]) = F_X(b) - F_X(a).
\]
Etwas mehr Vorsicht ist geboten bei Intervallen der Form $[a, b], [a, b)$ und $(a,b)$,
da die Endpunkte möglicherweise eine positive Wahrscheinlichkeit haben.
Dazu definieren wir noch die Funktion
\[
  F_X(r-) := \lim_{s \to r} F_X(s) = \Prob(X \in (-\infty, r)) = F_X(r) - \Prob(X = r).
\]
Dann gilt
\begin{align*}
  \Prob(X \in [a, b]) &= F_X(b) - F_X(a-) = F_X(b) - F_X(a) + \Prob(X = a), \\
  \Prob(X \in [a, b)) &= F_X(b-) - F_X(a-) = F_X(b) - F_X(a) - \Prob(X = b) + \Prob(X = a), \\
  \Prob(X \in (a, b)) &= F_X(b-) - F_X(a) = F_X(b) - F(X)(a) - \Prob(X = b).
\end{align*}

Während die Verteilungsfunktion uns sagt,
wie wahrscheinlich es ist, dass eine Zufallsvariable nicht grösser als ein
bestimmter Wert ist, liefert uns die \term{Quantilfunktion} $F^{-1}_X$ die umgekehrte
Information: Gegeben eine Zahl $p \in (0, 1)$
sagt sie uns, was der niedrigste Wert $q$ ist, sodass $F_X(q) \geq p$.
In Formeln:
\[
  F^{-1}_X(p) := \min\{q \in \mathbb{R} : F_X(q) \geq p\}.
\]
Abbildung \ref{fig:fx} kann man beispielsweise entnehmen, dass
$F_X^{-1}(0.4) = 3$ und $F_X^{-1}(7/9) = 8$.

\mypar[kontinuierliche Gleichverteilung]{Beispiel}
Beim Glücksrad aus Beispiel \ref{bsp:rad} können wir die Zufallsvariable
$X$ betrachten, die ganz einfach darstellt, bei welchem Wert der Pfeil
stehen bleibt. Die Verteilungsfunktion von $X$ (Abbildung \ref{fig:contuniform})
ist diesmal \term{stetig} (ohne Lücken). 
Das 0.3-Quantil dieser Verteilung liegt bei 108.
\parend
<<echo = FALSE, fig.cap = "Verteilungsfunktion der kontinuierlichen Gleichverteilung auf $[0, 360)$.\\label{fig:contuniform}",  fig.width = 4, fig.height = 3, out.width=".4\\textwidth">>=
curve(punif(x, 0, 360), from = -50, to = 410, xlab = "r", ylab = bquote(F[X](r)))
segments(-100, 0.3, qunif(0.3, 0, 360), col = "blue", lty = "dashed")
segments( qunif(0.3, 0, 360), 0.3, y1=0, col = "blue", lty = "dashed")
@


\subsection{Wahrscheinlichkeitsdichten}
Die Verteilung einer Zufallsvariablen $X$ mit einer stetigen Verteilungsfunktion
$F_X$ kann auch mittels einer \term{Wahrscheinlichkeitsdichte} $f_X$
dargestellt werden. 
Abbildung \ref{fig:kreisdichte} zeigt, was die Idee ist.
Wir wollen die Verteilung von $X$ so darstellen, dass
die Wahrscheinlichkeit, dass $X$ in einem bestimmten
Intervall liegt, gerade die Fläche unter der Wahrscheinlichkeitsdichte
in diesem Intervall ist.
Die Kerndichteschätzungen aus Kapitel \ref{ch:descriptives} sind eine Methode,
um anhand von Beobachtungen einer Zufallsvariablen die Wahrscheinlichkeitsdichte
ihrer Verteilung zu schätzen.

<<fig.cap = "Wahrscheinlichkeitsdichte einer kontinuierlichen Gleichverteilung mit Bereich 0 bis 360. Die Wahrscheinlichkeit, dass wir einen Wert zwischen 45 und 93 beobachten, entspricht der Fläche unter der Wahrscheinlichkeitsdichte in diesem Intervall.\\label{fig:kreisdichte}", echo = FALSE, fig.height = 2.8, fig.width = 4, message = FALSE, warning = FALSE, out.width="0.4\\textwidth">>=
op <- par(no.readonly = TRUE)
par(mar = c(3,4.1,2,1))
plot(0, 0, type = "n", xlab = "r", ylab = "", ylim = c(0, 1/360 + 1/900),
     xlim = c(-50, 410))
mtext(bquote(F[X](r)), side = 2, line = 3, las = 0, cex = 0.8)
segments(-100, 0, 0)
segments(0, 1/360, 360)
segments(360, 0, 500)
polygon(c(45, 45, 93, 93), c(0, 1/360, 1/360, 0), col = "lightgrey")
par(op)
@

Für die kontinuierliche Gleichverteilung auf $[0, 360)$ ist eine\footnote{Wahrscheinlichkeitsdichten sind nicht eindeutig definiert, aber zwei unterschiedliche Wahrscheinlichkeitsdichten zur gleichen Verteilung stimmen `fast überall' überein. `Fast überall' hat hierbei eine genaue mathematische Bedeutung, die uns jedoch zu weit führen würde.} Wahrscheinlichkeitsdichte
$f_X$ gegeben durch
\[
  f_X(x) = 
  \begin{cases}
    \frac{1}{360}, & \textrm{falls $x \in [0, 360)$}, \\
    0, & \textrm{sonst.}
  \end{cases}
\]
Wie Sie sich aus der Schule erinnern dürften,
entspricht diese Fläche dem Integral der Funktion über dieses Intervall.
Tatsächlich gilt
\[
  \Prob(X \in [45, 93]) = \int_{45}^{93} f_X(x) \df x = \int_{45}^{93} \frac{1}{360} \df x = \frac{93 - 45}{360}.
\]

Zufallsvariablen, deren Verteilung eine Wahrscheinlichkeitsdichte besitzt,
nennen wir \term{kontinuierlich}. Wir können auch sagen, dass ihre Verteilung
(absolut-)stetig ist.

\mypar{Bemerkung}
  Eine kontinuierliche Zufallsvariable kann nicht diskret sein und umgekehrt:
  Falls $X$ eine Wahrscheinlichkeitsdichte hat, so gilt
  \[
    \Prob(X = r) = \int_r^r f_X(x) \df x = 0
  \]
  für jedes $r$. Ist $X$ diskret, so muss es jedoch ein $r$ geben mit
  $\Prob(X = r) > 0$.

  Es existieren jedoch Zufallvariablen, die weder kontinuierlich noch diskret
  sind. Ein Beispiel einer solchen Zufallsvariablen ist die Niederschlagsmenge
  an einem bestimmten Tag in einem bestimmten Gebiet. So kann es beispielsweise
  eine Wahrscheinlichkeit von 70\% geben, dass es nicht regnet ($\Prob(X = 0) = 0.7$),
  während die Niederschlagsmenge, wenn es tatsächlich regnet, schon kontinuierlich
  verteilt ist.
\parend

\subsection{Der Erwartungswert und die Varianz}
Bevor wir uns ein paar klassische Wahrscheinlichkeitsverteilungen genauer
anschauen, wollen wir die zwei am häufigst verwendeten numerischen Merkmale
von Wahrscheinlichkeitsverteilungen genauer anschauen.
Das erste Merkmal ist der \term{Erwartungswert}. Dieser drückt aus,
welcher Wert Zufallsvariablen, die einer bestimmten Verteilung folgen,
im Schnitt annimmt. Der Erwartungswert ist die Verallgemeinerung
des arithmetischen Mittels auf beliebig grosse Grundräume bzw.\ Populationen.

Für eine diskrete Zufallsvariable $X$ auf einem Grundraum $\Omega$
kann der Erwartungswert $\E(X)$ wie folgt berechnet werden,
\[
  \E(X) = \sum_{x \in X(\Omega)} x\Prob(X = x),
\]
insofern diese Summe tatsächlich existiert. (Nicht alle Verteilungen
haben einen Erwartungswert. Mit solchen pathologischen Verteilungen werden
wir uns aber nicht auseinandersetzen.)
So gilt im Obenabe-Beispiel (Beispiel \ref{bsp:obenabe})
\begin{align*}
  \E(X) = 0\cdot \frac{1}{3} + 2 \cdot \frac{1}{9} + 3 \cdot \frac{1}{9}
          + 4 \cdot \frac{1}{9} + 8 \cdot \frac{1}{9} + 10 \cdot \frac{1}{9}
          + 11 \cdot \frac{1}{9}
        = 4.22.
\end{align*}
Ein weiteres Beispiel:
Sei $G$ die Zufallsvariable, die vom Zufallsgenerator aus Beispiel \ref{bsp:2k} generiert
wird. Ihr Erwartungswert beträgt
\[
  \E(G) = \sum_{k=1}^{\infty} k\Prob(G = k) = \sum_{k=1}^{\infty}\frac{k}{2^k} = 2.
\]
Erwartungswerte wie in diesem unendlichen Fall brauchen Sie für diesen Kurs
nicht selber berechnen zu können. Der Zweck des Beispiels ist lediglich,
zu zeigen, dass Erwartungswerte auch berechnet werden können, wenn die
Anzahl möglicher Werte unendlich gross ist.

Allgemeiner gilt übrigens, dass
\[
  \E(g(X)) = \sum_{x \in X(\Omega)} g(x)\Prob(X = x)
\]
für (grundsätzlich) jede Abbildung $g$, insofern diese Summe existiert.\footnote{Die Ausnahmen sind für uns in der Praxis nicht relevant.}

Hat die Verteilung der Zufallsvariablen $X$ eine Wahrscheinlichkeitsdichte $f_X$,
so berechnet man ihren Erwartungswert als
\[
  \E(X) = \int_{-\infty}^{\infty} xf_X(x) \df x,
\]
insofern dieses Integral tatsächlich existiert.
So gilt im Glücksradbeispiel
\begin{align*}
  \E(R)
  &= \int_{-\infty}^{\infty} x f_X(x) \df x \\
  &= \int_{0}^{360} \frac{x}{360} \df x \\
  &= \frac{1}{360} \left.\left[\frac{1}{2}x^2\right]\right|_0^{360} \\
  &= \frac{360^2}{2\cdot 360} \\
  &= 180.
\end{align*}

Auch hier gilt allgemeiner, dass
\[
  \E(g(X)) = \int_{-\infty}^{\infty} g(x)f_X(x) \df x,
\]
für (grundsätzlich) jede Abbildung $g$, insofern dieses Integral existiert.\footnote{Diese
Formel bezeichnet man übrigens manchmal als \textit{law of the unconscious statistician}.}
(Nicht alle Verteilungen
haben eine Varianz. Mit solchen pathologischen Verteilungen werden
wir uns aber nicht auseinandersetzen.)

Für Wahrscheinlichkeitsverteilungen, die weder kontinuierlich noch diskret sind,
kann man allenfalls den Erwartungswert separat für ihren kontinuierlichen und ihren
diskreten Teil berechnen, und dann mit einer geeigneten Gewichtung kombinieren.
Wir werden uns jedoch nur mit diskreten und kontinuierlichen Verteilungen
auseinandersetzen.

\mypar[Eigenschaften des Erwartungswerts]{Lemma}
Der Erwartungswert einer Konstanten $c$ ist gleich $c$, also $\E(c) = c$.

Der Erwartungswert ist wie bereits erwähnt \term{linear}.
Dies heisst, dass $\E(aX + bY) = a\E(X) + b\E(Y)$ für Konstanten $a, b$, insofern
$\E(X)$ und $\E(Y)$ existieren.
Diese Eigenschaft folgt aus der Linearität von endlichen und unendlichen
Summen und von Integralen.
\parend

Der Erwartungswert drückt aus, welcher Wert eine Zufallsvariable im Schnitt
annimmt. Es wäre jedoch nützlich, auch eine numerisches Mass zu haben, dass
ausdrückt, wie stark die Werte, die die Zufallsvariable annimmt, im Schnitt
von diesem Erwartungswert abweichen. Eine erste Idee dürfte sein, dass
wir dazu den Erwartungswert der Abweichungen berechnen, also
\[
  \E(X - \E(X)).
\]
Der Erwartungswert ist linear, also gilt
\[
  \E(X - \E(X)) = \E(X) - \E(\E(X)) = \E(X) - \E(X) = 0,
\]
und dies für jede Zufallsvariable mit einem Erwartungswert. Also liefert uns
diese Grösse keine Information. Sinnvoller wäre, den Erwartungswert der absoluten
Unterschiede zu berechnen, also
\[
  \E(|X - \E(X)|).
\]
Diese Grösse wird durchaus verwendet, ist aber eher schwierig zu hantieren.
Stattdessen arbeitet man meistens mit dem Erwartungswert der quadrierten Unterschiede,
also mit
\[
  \E((X - \E(X))^2).
\]
Diese Grösse nennt man die \term{Varianz} der Verteilung und
stellt eine Verallgemeinerung der Varianz aus Kapitel \ref{ch:descriptives}
auf beliebige Grundräume bzw.\ Populationen dar. 
Es gilt
\begin{align*}
  \Var(X)
  &= \E((X - \E(X))^2)                  & [\textrm{Definition}]\\
  &= \E(X^2 - 2X\E(X) + \E(X)^2)        & [\textrm{$(a-b)^2 = a^2 - 2ab + b^2$}] \\
  &= \E(X^2) - 2\E(X(\E(X))) + \E(X)^2  & [\textrm{Linearität von $\E$}] \\
  &= \E(X^2) - 2\E(X)^2 + \E(X)^2       & [\textrm{$\E(X)$ ist konstant}]\\
  &= \E(X^2) - \E(X)^2.                 &
\end{align*}

Die Varianz einer Zufallsvariablen, 
die in einer bestimmten Einheit ausgedrückt wird (z.B.\ Sekunden),
wird selber in quadrierten Einheiten ausgedrückt (z.B.\ quadrierten Sekunden).
Die Grösse $\sqrt{\Var(X)} =: \Std(X)$ nennt man die \term{Standardabweichung} von $X$
und wird in den gleichen Einheiten wie die Variable selbst ausgedrückt.

\mypar{Beispiel}
Im Obenabe-Beispiel haben wir
\begin{align*}
  \E(X^2) = 0^2\cdot \frac{1}{3} + 2^2 \cdot \frac{1}{9} + 3^2 \cdot \frac{1}{9}
          + 4^2 \cdot \frac{1}{9} + 8^2 \cdot \frac{1}{9} + 10^2 \cdot \frac{1}{9}
          + 11^2 \cdot \frac{1}{9}
        = 34.89.
\end{align*}
Daher beträgt die Varianz im Obenabe-Beispiel
\[
  \E(X^2) - \E(X)^2 = 34.89 - 4.22^2 = 17.08.
\]
Die Standardabweichung beträgt also etwa $4.13$.

Für den Zufallsgenerator aus Beispiel \ref{bsp:2k} gilt
\[
  \E(G^2) = \sum_{k=1}^n \frac{k^2}{2^k} = 6.
\]
Also beträgt die Varianz von $G$
\[
  \Var(G) = \E(G^2) - \E(G)^2 = 6 - 2^2 = 2.
\]

Im Glücksradbeispiel gilt
\[
  \E(R^2) = \int_{0}^{360}\frac{x^2}{360} \df x = \frac{360^3}{3\cdot 360} = 43200.
\]
Daher beträgt die Varianz
\[
  \E(R^2) - \E(R)^2 = 43200 - 180^2 = 10800.
\]
Die Standardabweichung beträgt etwa 103.9.
\parend

\mypar[Eigenschaften der Varianz]{Lemma}
  Für die Varianz gilt
  \[
    \Var(aX + b) = a^2\Var(X),
  \]
  für Konstanten $a, b$, falls $\Var(X)$ besteht.

  Im Allgemeinen gilt jedoch \emph{nicht}, dass $\Var(X + Y) = \Var(X) + \Var(Y)$.
  Dies gilt aber schon, wenn $X, Y$ unabhängig im Sinne des nächsten Abschnitts sind.
\parend

\mypar{Beispiel}
  Auf der Basis des Zufallsgenerators $G$ aus Beispiel \ref{bsp:2k}
  definieren wir die Zufallsvariable $\widetilde{G} := 3G + 4$.
  Dann 
  \[
    \E(\widetilde{G}) = \E(3G + 4) = 3\E(G) + 4 = 10
  \]
  und
  \[
    \Var(\widetilde{G}) = \Var(3G + 4) = 3^2\Var(G) = 18.
  \]
\parend

\mypar[Varianz einer Summe $\neq$ Summe der Varianzen]{Beispiel}
  Auf der Basis des Zufallsgenerators $G$ aus Beispiel \ref{bsp:2k}
  definieren wir die Zufallsvariable $\overline{G} := -G$.
  Dann gilt $G + \overline{G} = G - G = 0$.
  Also 
  \[
    \Var(G + \overline{G}) = 0 \neq 4 = \Var(G) + \Var(\overline{G}).
  \]
  Die Zufallsvariablen $G$ und $\overline{G}$ sind klar nicht unabhängig.
\parend

\subsection{Unabhängigkeit}
\mypar[Unabhängigkeit von Zufallsvariablen]{Definition}
  Seien $X, Y$ zwei Zufallsvariablen. Wir sagen, dass $X$ und $Y$ unabhängig sind,
  falls für jedes Paar von Zahlenmengen $E_1, E_2$ gilt,\footnote{Im Prinzip
  muss es überhaupt möglich sein, über die Ereignisse $X \in E_1, Y \in E_2$
  Wahrscheinlichkeitsaussagen machen zu können -- vgl.\ die Bemerkung auf
  Seite \pageref{comment:messbar}. Für unsere Zwecke ist diese Randbemerkung
  jedoch bloss eine Spitzfindigkeit, da es recht schwierig ist, eine Zahlmenge $E$
  zu konstruieren, sodass wir über das Ereignis $X \in E$ keine Wahrscheinlichkeitsaussagen machen können.} dass
  \[
    \Prob(X \in E_1, Y \in E_2) = \Prob(X \in E_1)\Prob(Y \in E_2).
  \]
  Die Definition von Unabhängigkeit von mehr als zwei Ereignissen lässt sich
  sinngemäss auf die Unabhängigkeit von mehr als zwei Zufallsvariablen übertragen.
\parend

Konzeptuell bedeutet die Unabhängigkeit von $X$ und $Y$, dass einem der Wert
von $X$ einem keinerlei Information darüber gibt, was der Wert von $Y$ ist
und umgekehrt.

\mypar{Lemma}
  Sind $X, Y$ unabhängige Zufallsvariablen mit existierender Varianz.
  Dann gilt
  \[
    \Var(X + Y) = \Var(X) + \Var(Y).
  \]
  Auf den Beweis verzichten wir hier.

  Die entsprechende Gleichung für den Erwartungswert
  gilt immer ($\E(X + Y) = \E(X) + \E(Y)$), bei der Varianz im Allgemeinen
  jedoch nur für unabhängige Variablen.
\parend

\section{Beispiele von diskreten Wahrscheinlichkeitsverteilungen}
Wir wollen uns nun einige klassische Wahrscheinlichkeitsverteilungen näher
anschauen.

\subsection{Die diskrete Gleichverteilung}
Sei $n$ eine natürlich Zahl und $\Omega := \{1, \dots, n\}$.
Gilt für jedes $k \in \Omega$, dass $\Prob(X = k) = 1/n$,
so hat $X$ eine diskrete Gleichverteilung über $\Omega$.
Wir schreiben $X \sim \textrm{Unif}(\Omega)$.

Das klassische Beispiel ist ein Würfelwurf mit einem sechsseitigen Würfel.
Es gilt $\Prob(X = k) = 1/6$ für $k \in \{1, 2, 3, 4, 5, 6\}$
und $\Prob(X = k) = 0$ für alle andere $k$.

Der Erwartungswert einer Zufallsvariablen $X$ mit einer diskreten Gleichverteilung mit Grundraum
$\{1, 2, \dots, n\}$ beträgt
\[
  \E(X) = \frac{1}{n}(1 + 2 + \dots + n) = \frac{n(1+n)}{2n} = \frac{1+n}{2},
\]
was wohl intuitiv einleuchtet.
Die Varianz dieser Zufallsvariablen beträgt
\[
  \Var(X) = \frac{n^2 - 1}{12},
\]
wobei wir uns die Herleitung dieser Tatsache schenken.

Allgemeiner gilt für eine Zufallsvariable $X$ mit einer diskreten Gleichverteilung auf
\[
  \Omega := \{a, a + 1, a + 2, \dots, b - 2, b - 1, b\},
\]
dass
\[
  \E(X) = \frac{a + b}{2}, \Var(X) = \frac{b^2 - 1}{12}.
\]

\mypar{Aufgabe}
  Sei $X$ eine Zufallsvariable mit einer diskreten Gleichverteilung
  auf 
  \[
  \{1, 2, \dots, n-1, n\}.
  \]
  Wir definieren $Y := X/2 + 1/2$.
  Dann hat $Y$ eine diskrete Gleichverteilung auf 
  \[
  \{1, 1.5, 2, \dots, n/2 - 0.5\}.
  \] 
  Verwenden Sie die Eigenschaften des Erwartungswerts und der Varianz,
  um $\E(Y), \Var(Y)$ zu bestimmen.
  
  Betrachten wir nun eine Zufallsvariable $Z \sim \textrm{Unif}(\Omega)$, wo
  \[
    \Omega = \{1, 1.5, 2, \dots, n/2 - 0.5, n/2\}.
  \]
  Bestimmen Sie $\E(Z), \Var(Z)$.
\parend

\mypar[Daten aus einer diskreten Gleichverteilung generieren]{Bemerkung}
  In späteren Kapiteln werden wir häufig Simulationen verwenden,
  um Konzepte zu verstehen und Daten auszuwerten. Für solche Situationen
  müssen wir Daten aus vorgegebenen Verteilungen generieren.
  Mit dem folgenden Vorgehen generieren wir \texttt{n\_obs} unabhängige
  Datenpunkte aus einer diskreten Gleichverteilung auf $\{1, \dots, n\}$.
<<>>=
# Grundraum definieren
n <- 6
Omega <- 1:n
# n_obs Datenpunkte aus Gleichverteilung auf {1, ..., n} generieren
n_obs <- 20
daten <- sample(Omega, n_obs, replace = TRUE)
daten
@
\parend

\subsection{Die Bernoulliverteilung}
Die \term{Bernoulliverteilung} beschreibt den Ausgang $X$ eines Zufallsexperiments mit
zwei möglichen Ergebnissen, die wir als $0$ und $1$ bezeichnen.
Sie hat einen Parameter $p \in [0, 1]$, die die Wahrscheinlichkeit einer $1$
ausdrückt. Also gelten $\Prob(X = 1) = p$ und $\Prob(X = 0) = 1-p$.
Folgt eine Zufallsvariable einer Bernoulliverteilung mit Parameter $p$,
so schreiben wir $X \sim \textrm{Bernoulli}(p)$.

Der Erwartungswert einer Bernoulli($p$)-verteilten Zufallsvariablen $X$
lässt sich einfach berechnen:
\[
  \E(X) = 0\cdot(1-p) + 1\cdot p = p.
\]
Ebenso gilt
\[
  \E(X^2) = 0^2\cdot(1-p) + 1^2\cdot p = p.
\]
Daher
\[
  \Var(X) = p - p^2 = p(1-p).
\]

\mypar{Beispiel}
  Ziehen wir eine Karte zufällig aus einem Blatt Jasskarten,
  so beträgt die Wahrscheinlichkeit, dass es sich um ein Ass handelt $p = 4/36 = 1/9$.
  Das Zufallsexperiment `Ass ziehen' können wir als Bernoulliexperiment mit
  Parameter $p$ modellieren, wobei wir das Ziehen eines Asses als 1 bezeichnen
  und das Nicht-Ziehen eines Asses als 0.
\parend

\subsection{Die Binomialverteilung}
Seien $X_1, \dots, X_n$ unabhängige Zufallsvariablen, die alle
Bernoulli($p$)-verteilt sind. Dann folgt $X := X_1 + \dots + X_n$
einer \term{Binomialverteilung} mit Parametern $n$ und $p$.
Wir schreiben $X \sim \textrm{Binomial}(n, p)$.
Die Binomialverteilung erfasst also, wie viele von $n$ unabhängigen
und identischen Bernoulliexperimenten erfolgreich ausgehen.

Wegen der Linearität des Erwartungswerts gilt
\[
  \E(X) = \E(X_1) + \dots + \E(X_n) = np.
\]
Wegen der Unabhängigkeit von $X_1, \dots, X_n$ gilt weiter
\[
  \Var(X) = np(1-p).
\]

Die Wahrscheinlichkeit, dass genau die ersten $k$ von $n$ unabhängigen und identischen
Bernoulliexperimenten Erfolge sind, beträgt
\[
  \Prob(X_1 = 1)\Prob(X_2 = 1) \dots \Prob(X_k = 1)\Prob(X_{k+1} = 0)\dots\Prob(X_n = 0) = p^k(1-p)^{n-k}.
\]
Es gibt $n!$ Möglichkeiten, die Bernoulliexperimente umzuordnen; siehe Beispiel \ref{bsp:factorial}.
Da die Ausgänge von $k$ bzw.\ $n-k$ Bernoulliexperimente nicht voneinander unterschieden werden
können, gibt es 
\[
  \frac{n!}{k!(n-k)!} =: \binom{n}{k}
\]
unterschiedliche mögliche Reihenfolgen, in denen die Ausgänge beobachtet werden können.
Insgesamt beträgt die Wahrscheinlichkeit, dass genau $k$ von $n$ unabhängigen und
identischen Bernoulliexperimenten Erfolge sind
\[
  \Prob(X = k) = \binom{n}{k}p^k(1-p)^{n-k}.
\]
Die Zahl $\binom{n}{k}$ nennen wir den Binomialkoeffizienten von $n$ und $k$
oder auch `$n$ tief $k$' oder `$n$ choose $k$'.
Für $k < 0$ oder $k > n$ definieren wir $\binom{n}{k} = 0$.
Die Verteilungsfunktion einer Binomial($n$, $p$)-Verteilung ist folglich gegeben durch
\[
  F(r) = \sum_{k = 0}^{\lfloor r \rfloor} \binom{n}{k}p^k(1-p)^{n-k}.
\]

Der Binomialkoeffizient $\binom{n}{k}$ kann mit dem R-Befehl \texttt{choose(n, k)}
berechnet werden.
Auch eingebaut in R sind einige Funktionen, mit denen man Informationen über
die Binomialverteilung abfragen kann und binomialverteilte Zufallsdaten
generieren kann. Als Beispiel können wir uns hier vorstellen, dass 
wir 10 Mal mit einem 6-seitigen Würfel werfen und dabei zählen, wie oft
wir eine 6 würfeln. Dies entspricht einer Binomial($10$, $1/6$)-Verteilung.
Mit der Funktion \texttt{dbinom()} können wir $\Prob(X = k)$ abfragen.
Beispielsweise beträgt die Wahrscheinlichkeit, dass wir genau fünf Mal eine
6 würfeln ungefähr 1.3\%.
<<>>=
dbinom(5, 10, 1/6)
@
Abbildung \ref{fig:dbinom} zeigt diese Wahrscheinlichkeit für $k = 0, \dots, 10$.
<<fig.cap = "Wahrscheinlichkeit der Anzahl Erfolg bei einer Binomial($10$, $1/6$)-Verteilung.\\label{fig:dbinom}", fig.width = 4, fig.height = 3, out.width=".4\\textwidth">>=
k <- 0:10
plot(k, dbinom(k, 10, 1/6), pch = 16,
     xlab = "k", ylab = "Prob(X = k)")
@

Mit \texttt{pbinom()} können wir $\Prob(X \leq k)$ abfragen.
So finden wir heraus, dass die Wahrscheinlichkeit, dass wir höchstens zwei
Mal eine 6 würfeln, etwa 78\% beträgt.
<<>>=
pbinom(2, 10, 1/6)
@
Die Wahrscheinlichkeit, dass wir mehr als zwei Sechsen würfeln, beträgt
also etwa 22\%. Die Wahrscheinlichkeit, dass wir mindestens zwei Sechsen
würfeln beträgt etwa 52\%.
<<>>=
1 - pbinom(1, 10, 1/6)
pbinom(1, 10, 1/6, lower.tail = FALSE)
@

Mit \texttt{qbinom()} können wir die Quantile der Binomial($n$, $p$)-Verteilung
abfragen:
<<>>=
qbinom(0.70, 10, 1/6)
qbinom(0.75, 10, 1/6)
qbinom(0.80, 10, 1/6)
@
Mit anderen Worten: Wenn zig Leute je 10 Mal würfeln, werden mindestens 70\% 
unter ihnen höchstens zwei Sechsen würfeln. Sogar werden mindestens 75\%
unter ihnen höchstens zwei Sechsen würfeln. Mindestens 80\% unter ihnen
werden höchstens drei Sechsen würfeln. Tatsächlich werden ungefähr
77.5\% höchstens zwei Sechsen würfeln, wie wir mit \texttt{pbinom()} ausrechnen
können:
<<>>=
k <- 0:10
tibble(k = k, 
       "Prob(X <= k)" = pbinom(k, 10, 1/6))
@

Mit \texttt{rbinom()} können wir unabhängige Beobachtungen 
aus einer Binomialverteilung generieren. Beispielsweise können wir uns
vorstellen, dass 20 Personen alle 10 Mal würfeln und zählen, wie oft
sie eine 6 bekommen:
<<>>=
rbinom(20, 10, 1/6)
@

Die Bernoulli($p$)-Verteilung ist die gleiche Verteilung wie 
die Binomial($1$, $p$)-Verteilung.

\section{Beispiele von kontinuierlichen Wahrscheinlichkeitsverteilungen}
\subsection{Die kontinuierliche Gleichverteilung}
Die kontinuierliche Gleichverteilung, auch Uniformverteilung genannt, 
haben wir bereits im Glücksradbeispiel kennengelernt.
Allgemeiner bezeichnen wir mit Unif($[a,b]$) die kontinuierliche
Gleichverteilung auf dem Intervall $[a,b], a \leq b$. Die Endpunkte kann
man zum Intervall rechnen oder auch nicht; die Verteilung ändert sich dadurch
nicht. Für $X \sim \textrm{Unif}([a,b])$ gelten
\[
  \E(X) = \frac{b-a}{2}
\]
und 
\[
  \Var(X) = \frac{(b-a)^2}{12}.
\]
Eine Wahrscheinlichkeitsdichte einer Gleichverteilung auf $[a,b]$ ist gegeben
durch
\[
  f_U(x) = 
  \begin{cases}
    \frac{1}{b-a}, & \textrm{falls $x \in [a, b]$}, \\
    0, &\textrm{sonst}.
  \end{cases}
\]
Die Verteilungsfunktion ist
\[
  F_U(r) =
  \begin{cases}
    0, & \textrm{falls $r < a$}, \\
    \frac{r - a}{b-a}, & \textrm{falls $r \in [a,b]$}, \\
    1, & \textrm{falls $r > b$}.
  \end{cases}
\]

Die Wahrscheinlichkeitsdichte können wir mit \texttt{dunif()} abfragen,
hier für eine Gleichverteilung auf $[-\pi, \pi]$:
<<>>=
dunif(2, -pi, pi) # = 1/(2*pi)
dunif(4, -pi, pi)
@
Die Verteilungsfunktion ist in \texttt{punif()} implementiert:
<<>>=
punif(2, -pi, pi)
@
Das heisst, bei einer Unif($[-\pi, \pi$])-Verteilung beträgt die Wahrscheinlichkeit,
einen Wert unter (oder nicht grösser als) 2 zu beobachten, etwa 82\%.
Mit \texttt{qunif()} können wir die Quantile von kontinuierlichen Gleichverteilungen berechnen
und \texttt{runif()} können unabhängige Beobachtung aus kontinuierlichen
Gleichverteilungen generiert werden:
<<>>=
runif(10, -pi, pi)
@


\subsection{Die Normalverteilung}
Von grosser praktischer Bedeutung sind \term{Normalverteilungen}, wie wir im nächsten
Abschnitt sehen werden.
Normalverteilungen werden durch zwei Parameter
definiert: ihr Erwartungswert $\mu$ und ihre Varianz $\sigma^2$.
Hat eine Zufallsvariable $X$ eine Normalverteilung mit Parametern $\mu, \sigma^2$,
so schreibt man $X \sim \textrm{Normal}(\mu, \sigma^2)$ oder $X \sim \mathcal{N}(\mu, \sigma^2)$.
Abbildung \ref{fig:dnorm} zeigt die Wahrscheinlichkeitsdichten von vier 
Normalverteilungen. Links oben sehen Sie die \term{Standardnormalverteilung},
das heisst, die Normalverteilung mit Mittel 0 und Varianz 1.

<<echo = FALSE, fig.cap = "Wahrscheinlichkeitsdichten von vier Normalverteilungen.\\label{fig:dnorm}", fig.width = 4, fig.height = 3, out.width=".4\\textwidth">>=
op <- par(no.readonly = TRUE)
par(mfrow = c(2, 2))
curve(dnorm(x), from = -6, to = 6, ylab = "f(x)", ylim = c(0, 0.42), main = "N(0, 1)")
curve(dnorm(x, mean = 2), from = -6, to = 6, ylab = "f(x)", ylim = c(0, 0.42), main = "N(2, 1)")
curve(dnorm(x, sd = sqrt(3)), from = -6, to = 6, ylab = "f(x)", ylim = c(0, 0.42), main = "N(1, 3)")
curve(dnorm(x, mean = 2, sd = sqrt(3)), from = -6, to = 6, ylab = "f(x)", ylim = c(0, 0.42), main = "N(2, 3)")
par(op)
@

Die Wahrscheinlichkeitsdichte $f$ einer $\mathcal{N}(\mu, \sigma^2)$-Verteilung sieht anfangs wie
ein Schrecksgespenst aus:
\[
  f(x) = \frac{1}{\sqrt{2\pi}\sigma}\exp\left\{\frac{-(x-\mu)^2}{2\sigma}\right\},
\]
wobei $\exp\{\cdot\}$ die Exponentialfunktion ist. 
Wichtig ist diese Formel für uns jedoch nicht;
es reicht, dass Sie einsehen, dass der Parameter $\mu$ die zentrale Lage der Normalverteilung
regelt und $\sigma^2$ wie hoch und breit sie ist. Normalverteilungen haben keine Verteilungsfunktion,
die man analytisch darstellen kann.

In R stehen uns die Funktionen \texttt{dnorm()}, \texttt{pnorm()} und \texttt{rnorm()}
zur Verfügung für die Wahrscheinlichkeitsdichte und Verteilungsfunktion bzw.\ fürs Generieren 
von unabhängigen Beobachtungen aus Normalverteilungen. Dabei ist jedoch zu beachten, dass
Normalverteilungen in R nicht durch ihre Varianz, sondern durch ihre Standardabweichung parametrisiert
werden. Sei beispielsweise $X \sim \mathcal{N}(3, 16)$. 
So können wir $\Prob(X \leq 0)$ wie folgt berechnen; siehe auch Abbildung \ref{fig:dnormex}:
<<>>=
pnorm(0, mean = 3, sd = sqrt(16))
@

<<echo = FALSE, fig.cap = "Die $\\mathcal{N}(3, 16)$-Verteilung. Die Wahrscheinlichkeit, einen Wert unter 0 anzutreffen, entspricht der Fläche unter der Wahrscheinlichkeitsdichte bis 0.\\label{fig:dnormex}", fig.width = 4, fig.height = 2.8, out.width=".4\\textwidth">>=
library(RColorBrewer)
ggplot(data.frame(x = c(-12, 18)),
             aes(x)) +
  stat_function(fun = function(x) dnorm(x, mean = 3, sd = sqrt(16))) +
  ylab("f(x)") +
  stat_function(fun = function(x) {
    y <- dnorm(x, 3, sqrt(16))
    y[x > 0] <- NA
    return(y)
  }, geom = "area", fill = "blue", alpha = 0.2)
@


\mypar[IQ]{Aufgabe} Die Verteilung der IQ-Werten in der Gesamtpopulation 
wird durch eine $\mathcal{N}(100, 15^2)$-Verteilung modelliert.
Verwenden Sie die \texttt{pnorm()}- und \texttt{qnorm()}-Funktionen, um
folgende Fragen zu beantworten. Für die letzten drei Fragen könnten Sie
zusätzlich auch noch die Binomialverteilung heranziehen, aber Sie können
diese Aufgaben auch `zu Fuss' lösen.
\begin{enumerate}
\item Wie wahrscheinlich ist es, dass eine zufällig ausgewählte Person einen IQ niedriger als 90 hat?
\item Wie wahrscheinlich ist es, dass eine zufällig ausgewählte Person einen IQ grösser als 85 hat?
\item Wie wahrscheinlich ist es, dass eine zufällig ausgewählte Person einen IQ zwischen 110 und 120 hat?
\item Wie wahrscheinlich ist es, dass eine zufällig ausgewählte Person einen IQ hat, der mindestens eine Standardabweichung (also 15 IQ-Punkte)
unter dem Mittel liegt?
\item Wie wahrscheinlich ist es, dass eine zufällig ausgewählte Person einen IQ hat, der mindestens eine Standardabweichung (also 15 IQ-Punkte)
vom Mittel entfernt liegt?
\item Für welchen IQ-Wert gilt, dass 25\% der Bevölkerung einen niedrigeren IQ-Wert hat?
\item Durchschnittliche Intelligenz ist definiert als der IQ der mittleren 45\% der Bevölkerung. 
Zwischen welchen zwei Werten liegt er?

\item 
Wie wahrscheinlich ist es, dass, wenn zwei Personen zufällig und unabhängig voneinander ausgewählt werden, keine der beiden einen IQ niedriger als 105 hat?

Tipp: Wie wahrscheinlich ist es, dass eine einzige Person einen IQ höher als 105 hat?
\item Wie wahrscheinlich ist es, dass, wenn drei Personen zufällig ausgewählt werden, \emph{genau} eine Person einen IQ niedriger als 90 hat?

\item Wie wahrscheinlich ist es, dass, wenn drei Personen zufällig ausgewählt werden, \emph{mindestens} eine Person einen IQ niedriger als 90 hat? \parend
\end{enumerate}

\mypar{Aufgabe}
Wie wahrscheinlicht ist es, bei einer normalverteilten Variable (\emph{egal welcher!}) einen zufällig ausgewählten Wert, der weniger als 1; 1,5; und 2 Standardabweichungen vom Mittel entfernt ist, anzutreffen?

Tipp: 
Beantworten Sie diese Frage für ein paar Normalverteilungen mit 
unterschiedlichen Mitteln und Standardabweichungen
und ziehen Sie eine allgemeine Schlussfolgerung.
\parend

\section{Der zentrale Grenzwertsatz}\label{sec:clt}
Wir greifen das Glücksradbeispiel wieder auf.
Nehmen wir an, dass $n$ Leute unabhängig voneinander je ein Mal mit diesem
Glücksrad spielen. Dann erhalten wir unabhängige und identisch
verteilte Zufallsvariablen $X_1, X_2, \dots, X_n \sim \textrm{Unif}([0, 360))$.
Können wir nun etwas Vernünftiges über ihr durchschnittliches Resultat,
also über
\[
  \overline{X} = \frac{X_1 + \dots + X_n}{n},
\]
sagen?

Die Antwort ist `ja'. Aufgrund der Linearität des Erwartungswerts gilt erstens
\begin{align*}
  \E(\overline{X})
  &= \E\left(\frac{X_1 + \dots + X_n}{n}\right) \\
  &= \frac{1}{n}\E(X_1 + \dots + X_n) \\
  &= \frac{1}{n}(\E(X_1) + \dots + \E(X_n)) \\
  &= \frac{n}{n}\E(X_1) \\
  &= \E(X_1).
\end{align*}
In diesem konkreten Beispiel also $\E(\overline{X}) = 180$.

Zweitens gilt wegen der Unabhängigkeit, dass
\begin{align*}
  \Var(\overline{X})
  &= \Var\left(\frac{X_1 + \dots + X_n}{n}\right) \\
  &= \frac{1}{n^2}\Var(X_1 + \dots + X_n) \\
  &= \frac{1}{n^2}(\Var(X_1) + \dots + \Var(X_n)) \\
  &= \frac{n}{n^2}\Var(X_1) \\
  &= \frac{\Var(X_1)}{n}.
\end{align*}
In diesem konkreten Beispiel also $\sigma^2_{\overline{X}} := \Var(\overline{X}) = \frac{360^2}{12n}$.

Diese Erkenntissen sind allgemeingültig, wenn wir $n$ unabhängige und identisch
verteilte Zufallsvariablen aus einer Verteilung mit existierendem Erwartungswert
und endlicher Varianz mitteln:
\[
  \mu_{\overline{X}} = \E(\overline{X}) = \E(X_1)
\]
und
\[
  \sigma_{\overline{X}}^2 = \Var(\overline{X}) = \frac{1}{n}\Var(X_1).
\]
Die Grösse $\sigma_{\overline{X}} := \Std(\overline{X}) = \sqrt{\Var(\overline{X})}$
nennt man den \term{Standardfehler} (des Mittels). Es gilt also
\[
  \sigma_{\overline{X}} = \frac{\sigma}{\sqrt{n}}.
\]

\mypar{Aufgabe}
  Stellen Sie sich vor, dass 10 Leute unabhängig voneinander eine Zahl
  mit dem Zufallsgenerator aus Beispiel \ref{bsp:2k} generieren.
  Was ist der Erwartungswert der Zahl, die sie im Schnitt generieren?
  Was ist der Standardfehler dieses Mittels?
  
  Hinweis: Den Erwartungswert und die Varianz einer einzelnen generierten
  Zahl haben wir bereits berechnet.
\parend

Was können wir noch über die Verteilung von $\overline{X}$ sagen?
Eine Möglichkeit, diese besser zu verstehen, besteht darin, das Zufallsexperiment
mehrmals am Computer zu \term{simulieren}. Dazu definieren wir zunächst eine
Funktion, die das Zufallsexperiment ein Mal simuliert:
<<>>=
wheel_one_run <- function(n, min = 0, max = 360) {
  x <- runif(n, min, max)
  return(mean(x))
}
@
Diese Funktion führen wir nun 10'000 Mal aus, hier mit $n = 2$:
<<>>=
simulation <- replicate(10000, wheel_one_run(n = 2))
@
Mit \texttt{hist()} können wir schnell ein Histogramm 
von \texttt{simulation} zeichnen, ohne dass wir zuerst noch ein \textit{tibble}
zusammenbasteln müssen. Das Resultat ist Abbildung \ref{fig:mittelglucksrad}.
<<fig.cap = "Verteilung des Mittels von zwei Drehen am Glücksrad.\\label{fig:mittelglucksrad}", fig.width = 4, fig.height = 3, out.width=".4\\textwidth">>=
hist(simulation, freq = FALSE, xlim = c(0, 360),
     xlab = "Mittel", ylab = "Wsk.-Dichte", main = "")
@

\mypar[$n$ vergrössern]{Aufgabe}
  Führen Sie die gleiche Simulation durch, aber diesmal mit
  $n = 5, 25, 100$. Wie sehen die Histogramme aus?
\parend

\mypar[Obenabe-Spiel]{Aufgabe}
Schauen wir uns ein weiteres Beispiel an: Nehmen wir an, $n$
Leute ziehen je eine Karte aus je einem Jassblatt von 36 Karten.
Wir bezeichnen mit $\overline{X}$ die durchschnittliche Punktzahl,
die die gezogenen Karten beim Obenabe-Spiel wert sind; vgl.\ Beispiel
\ref{bsp:obenabe}. Die entsprechende Simulation können wir wie folgt
durchführen:
<<eval = FALSE>>=
werte <- c(11, 4, 3, 2, 10, 8, 0)
wsk <- c(1/9, 1/9, 1/9, 1/9, 1/9, 1/9, 1/3)
jass_one_run <- function(n, values = werte, probs = wsk) {
  x <- sample(values, n, replace = TRUE, prob = probs)
  mean(x)
}
# Simulation für n = 2
simulation <- replicate(10000, jass_one_run(2))
hist(simulation, freq = FALSE, xlim = c(0, 11),
     xlab = "Mittel", ylab = "Wsk.-Dichte", main = "")
@

Führen Sie diese Simulation durch für $n = 4, 8, 16$. 
Wie sehen die Histogramme aus?
\parend

Das Fazit, das man aus diesen beiden Aufgaben ziehen kann,
ist als der zentrale Grenzwertsatz bekannt.
`Zentral' bezieht sich hier auf die Wichtigkeit des Satzes, nicht
auf den Grenzwert; `zentrale Grenzwerte' gibt es nicht.

\mypar[zentraler Grenzwertsatz]{Satz}
  Seien $X_1, \dots, X_n$ unabhängige und identisch verteilte Zufallsvariablen
  mit existierendem Erwartungswert $\mu$ und endlicher Varianz $\sigma^2$.
  Dann gilt: Für $n \to \infty$ nähert sich die Verteilung von
  $\overline{X}_n = \frac{1}{n}(X_1 + \dots + X_n)$ der Normalverteilung $\mathcal{N}(\mu, \sigma^2/n)$.
\parend

Das Mittel $\overline{X}_n$ von $n$ unabhängigen Beobachtungen einer nicht-pathologischen
Zufallsvariablen $X$ ist also selber eine Zufallsvariable, deren
Verteilung ungefähr normalverteilt aussieht, wenn $n$ `gross genug' ist.
Dies gilt auch dann, wenn die Verteilung von $X$ selber nicht normal ist.
Die praktische Bedeutung hiervon ist, dass wir die Normalverteilung verwenden können,
um approximative Aussagen über die Wahrscheinlichkeit, bestimmte Mittel zu beobachten,
zu machen.

\mypar[`gross genug']{Bemerkung}
Der Ausdruck `gross genug' wirkt zunächst ungenau.
Tatsächlich ist die Aussage des zentralen Grenzwertsatzes \emph{nicht},
dass das Mittel von $n$ Beobachtungen normalverteilt ist.
Im Glücksradbeispiel können wir kein Mittel niedriger als 0 oder grösser
als 360 erhalten, während jede Normalverteilung dieser Möglichkeit eine
vielleicht äusserst kleine, aber dennoch positive Wahrscheinlichkeit zuordnen
würde. Im Obenabe-Beispiel kann das Mittel von $n$ Werten nur eine Bruchzahl
sein, während eine Zufallsvariable mit einer Normalverteilung jeden Wert
annehmen kann.
Was stattdessen gemeint ist, ist dies:
Für jede positive Fehlermarge $\varepsilon > 0$
existiert laut dem zentralen Grenzwertsatz eine natürliche Zahl $N$,
sodass für jede natürliche Zahl $n \geq N$ gilt, dass
\[
\Prob\left(\frac{1}{n}(X_1 + \dots + X_n) \leq r \right)
\]
um höchstens $\varepsilon$ abweicht von 
\[
  \Prob(\mu + \sigma_{\overline{X}}Z \leq r),
\]
wobei $\mu + \sigma_{\overline{X}}Z$ normalverteilt ist mit Mittel $\mu = \E(X_1)$ und Varianz $\sigma^2_{\overline{X}} = \sigma^2/n$; 
dies für jede Zahl $r$.\footnote{Die Aussage ist übrigens, dass ein solche Zahl $N$ existiert -- nicht, dass wir sie auch einfach finden können.}
Folglich können wir Wahrscheinlichkeiten wie
\[
\Prob(\overline{X} \in [a, b])
\]
anhand einer Normalverteilung schätzen. Für grössere $n$ ist diese Schätzung genauer.
\parend

\mypar[Würfelwurf]{Beispiel}
  Die Anzahl Augen, die man beim Würfeln mit einer 6-seitigen Würfel erhält, folgt einer
  diskreten Gleichverteilung auf $\{1, 2, 3, 4, 5, 6\}$. Ein Wurf hat Erwartungswert $\mu = 3.5$
  und Varianz $\sigma^2 \approx 2.92$. Wenn wir 7 Mal würfeln, beträgt die Varianz
  des durchschnittlichen Wurf $\sigma^2/7 \approx 0.42$.
  Die Wahrscheinlichkeit, dass der durchschnittliche Wurf kleiner als 3 ist,
  beträgt mit dem zentralen Grenzwertsatz ungefähr 22\%.
<<>>=
pnorm(3, mean = 3.5, sd = sqrt(0.42))
@
  Die Wahrscheinlichkeit, dass der Durchschnitt grösser als 4.5 ist, beträgt etwa
  6\%.
<<>>=
1 - pnorm(4.5, 3.5, sd = sqrt(0.42))
@
  Die Wahrscheinlichkeit, dass der Durchschnitt zwischen 3 und 4.5 liegt,
  ist also etwa $1 - 0.22 - 0.06 \approx 0.72$, also 72\%.
  
  Die möglichen Mittel aus sieben Würfen können alle als Bruchzahl mit
  Nenner 7 geschrieben werden. Insbesondere ist es nicht möglich, dass
  das Mittel zwischen $3+\frac{1}{3\cdot 7}$ und $3 + \frac{2}{3\cdot 7}$ liegt.
  Mit der normalen Annäherung fänden wir jedoch, dass diese Wahrscheinlichkeit
  bei etwa 2.4\% und nicht bei 0\% liegt.
<<>>=
pnorm(3 + 2/21, 3.5, sd = sqrt(0.42)) - pnorm(3 + 1/21, 3.5, sd = sqrt(0.42)) 
@
\parend

\mypar{Aufgabe}
  Wir generieren $n$ unabhängige Zahlen mit dem Zufallsgenerator aus
  Beispiel \ref{bsp:2k}. Es gilt also $\mu = 2, \sigma^2 = 2$.
  \begin{enumerate}
    \item Sei $n = 2$. Wie gross ist die Wahrscheinlichkeit, dass
    die durchschnittliche Zahl kleiner als $1/2$ ist? Was wäre unsere
    Schätzung für diese Wahrscheinlichkeit, wenn wir den zentralen
    Grenzwertsatz anwenden würden?
    
    \item Gleiche Fragen für $n = 20$ und $n = 200$.
    
    \item Sei $n = 30$. Wie gross ist laut dem zentralen Grenzwertsatz
    die Wahrscheinlichkeit, dass die durchschnittliche Zahl zwischen 1.8 und 2.2 liegt?\parend
  \end{enumerate}
